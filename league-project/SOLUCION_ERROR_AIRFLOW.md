# üîß Soluci√≥n: Error en DAGs de Airflow

## ‚ùå Problema Identificado

**Error:** Los DAGs de Airflow fallaban con el mensaje:
```
Task ID: run_eda_pipeline
Status: failed
Duration: 00:00:00
```

## üîç Diagn√≥stico

### **Causa Ra√≠z:**
Los DAGs estaban configurados con una ruta incorrecta al proyecto Kedro:

```python
# ‚ùå INCORRECTO:
bash_command='cd /opt/airflow/kedro_project && kedro run --pipeline eda'
```

**Problema:** La ruta `/opt/airflow/kedro_project` no existe en el contenedor Docker.

### **Ruta Correcta:**
Seg√∫n el `docker-compose.yml`, el proyecto se monta en `/app`:

```yaml
volumes:
  - ./data:/app/data
  - ./conf:/app/conf
  - ./src:/app/src
```

## ‚úÖ Soluci√≥n Aplicada

### **Archivos Corregidos:**

#### 1. `airflow/dags/kedro_eda_only_dag.py`
```python
# ‚úÖ CORRECTO:
eda_task = BashOperator(
    task_id='run_eda_pipeline',
    bash_command='cd /app && kedro run --pipeline eda',
    dag=dag,
)
```

#### 2. `airflow/dags/kedro_league_ml_dag.py`
```python
# ‚úÖ CORRECTO:
data_cleaning_task = BashOperator(
    task_id='data_cleaning',
    bash_command='cd /app && kedro run --pipeline data_cleaning',
    dag=dag,
)

data_exploration_task = BashOperator(
    task_id='data_exploration',
    bash_command='cd /app && kedro run --pipeline data_exploration',
    dag=dag,
)

# ... (todos los dem√°s tasks corregidos)
```

#### 3. `airflow/dags/kedro_training_only_dag.py`
```python
# ‚úÖ CORRECTO:
def check_processed_data(**context):
    data_path = '/app/data/05_model_input/model_input_table.parquet'
    # ...

process_data_task = BashOperator(
    task_id='process_data',
    bash_command='cd /app && kedro run --pipeline data_processing',
    dag=dag,
)

train_models_task = BashOperator(
    task_id='train_models',
    bash_command='cd /app && kedro run --pipeline data_science',
    trigger_rule='none_failed_or_skipped',
    dag=dag,
)

evaluate_models_task = BashOperator(
    task_id='evaluate_models',
    bash_command='cd /app && kedro run --pipeline evaluation',
    dag=dag,
)
```

---

## üöÄ Pasos para Aplicar la Correcci√≥n

### **Opci√≥n 1: Reiniciar Airflow (Recomendado)**

```powershell
# 1. Detener los servicios
docker-compose down

# 2. Reiniciar los servicios
docker-compose up -d

# 3. Verificar que los DAGs est√°n cargados
docker-compose logs airflow-scheduler | Select-String "DAG"

# 4. Acceder a Airflow UI
# http://localhost:8080
# Usuario: admin
# Password: admin
```

### **Opci√≥n 2: Reiniciar Solo el Scheduler**

```powershell
# Reiniciar solo el scheduler (m√°s r√°pido)
docker-compose restart airflow-scheduler

# Verificar logs
docker-compose logs -f airflow-scheduler
```

### **Opci√≥n 3: Forzar Recarga de DAGs**

```powershell
# Entrar al contenedor del scheduler
docker-compose exec airflow-scheduler bash

# Dentro del contenedor:
airflow dags reserialize

# Salir
exit
```

---

## üß™ Verificaci√≥n

### **1. Verificar que los DAGs est√°n activos**

```powershell
# Listar todos los DAGs
docker-compose exec airflow-scheduler airflow dags list
```

**Salida esperada:**
```
kedro_eda_pipeline
kedro_league_ml_pipeline
kedro_model_training_pipeline
```

### **2. Verificar configuraci√≥n de un DAG**

```powershell
# Ver detalles de un DAG espec√≠fico
docker-compose exec airflow-scheduler airflow dags show kedro_eda_pipeline
```

### **3. Ejecutar un DAG manualmente (Test)**

```powershell
# Trigger manual desde CLI
docker-compose exec airflow-scheduler airflow dags test kedro_eda_pipeline 2024-10-27
```

### **4. Verificar en la UI de Airflow**

1. Abre http://localhost:8080
2. Login: `admin` / `admin`
3. Ve a la lista de DAGs
4. Verifica que los 3 DAGs aparecen sin errores
5. Click en `kedro_eda_pipeline`
6. Click en "‚ñ∂Ô∏è Trigger DAG"
7. Monitorea en "Graph View"

---

## üìä Estado Esperado Despu√©s de la Correcci√≥n

### **DAG: kedro_eda_pipeline**
```
Status: ‚úÖ Success
Task ID: run_eda_pipeline
Duration: ~3 minutes
Output: Reportes en data/08_reporting/
```

### **DAG: kedro_league_ml_pipeline**
```
Status: ‚úÖ Success
Tasks:
  ‚úÖ data_cleaning (~1 min)
  ‚úÖ data_exploration (~2 min)
  ‚úÖ data_processing (~2 min)
  ‚úÖ model_training (~8 min)
  ‚úÖ model_evaluation (~2 min)
  ‚úÖ generate_final_report (<1 min)
Total Duration: ~15 minutes
```

### **DAG: kedro_model_training_pipeline**
```
Status: ‚úÖ Success
Tasks:
  ‚úÖ check_data (<1 min)
  ‚úÖ train_models (~8 min)
  ‚úÖ evaluate_models (~2 min)
Total Duration: ~10 minutes
```

---

## üîç Troubleshooting Adicional

### **Problema 1: DAG sigue fallando**

**Verificar logs del scheduler:**
```powershell
docker-compose logs airflow-scheduler | Select-String "ERROR"
```

**Verificar logs de la tarea espec√≠fica:**
```powershell
docker-compose logs airflow-worker | Select-String "kedro"
```

### **Problema 2: DAG no aparece en la UI**

**Verificar que el archivo est√° en la carpeta correcta:**
```powershell
dir airflow\dags
```

**Salida esperada:**
```
kedro_eda_only_dag.py
kedro_league_ml_dag.py
kedro_training_only_dag.py
```

**Verificar sintaxis del DAG:**
```powershell
docker-compose exec airflow-scheduler python /opt/airflow/dags/kedro_eda_only_dag.py
```

### **Problema 3: Kedro no encuentra los datos**

**Verificar vol√∫menes montados:**
```powershell
docker-compose exec kedro-app ls -la /app/data/01_raw/
```

**Salida esperada:**
```
champions_stats.csv
matches_stats.csv
players_stats.csv
...
```

### **Problema 4: Permisos de archivos**

```powershell
# Windows puede tener problemas de permisos
# Verifica que Docker Desktop tiene acceso a la carpeta

# En Docker Desktop:
Settings ‚Üí Resources ‚Üí File Sharing
# Aseg√∫rate de que C:\Users\pedri\OneDrive\Desktop est√° compartido
```

---

## üìù Prevenci√≥n de Errores Futuros

### **Checklist al crear nuevos DAGs:**

- [ ] Usar ruta `/app` para el proyecto Kedro
- [ ] Verificar que el comando kedro funciona: `cd /app && kedro run`
- [ ] Probar el DAG con `airflow dags test`
- [ ] Verificar logs despu√©s de la primera ejecuci√≥n
- [ ] Documentar cualquier configuraci√≥n especial

### **Template de BashOperator correcto:**

```python
# ‚úÖ Template recomendado:
task_name = BashOperator(
    task_id='descriptive_task_id',
    bash_command='cd /app && kedro run --pipeline PIPELINE_NAME',
    dag=dag,
)
```

---

## üéì Lecciones Aprendidas

### **1. Consistencia de Rutas**
- Docker monta el proyecto en `/app`
- Todos los comandos deben usar esta ruta
- Revisar `docker-compose.yml` para confirmar vol√∫menes

### **2. Testing de DAGs**
- Siempre probar DAGs con `airflow dags test` antes de deploy
- Verificar logs del scheduler regularmente
- Usar Airflow UI para monitoreo visual

### **3. Documentaci√≥n**
- Documentar rutas y configuraciones espec√≠ficas
- Mantener este documento actualizado con nuevos errores
- Compartir soluciones con el equipo

---

## üìö Referencias

### **Documentaci√≥n Relacionada:**
- `DOCKER_AIRFLOW_GUIDE.md` - Gu√≠a completa de Docker y Airflow
- `QUICK_START.md` - Inicio r√°pido
- `README_COMPLETO.md` - Gu√≠a t√©cnica exhaustiva

### **Recursos Oficiales:**
- [Apache Airflow Docs](https://airflow.apache.org/docs/)
- [Kedro Docs](https://kedro.readthedocs.io/)
- [Docker Compose Docs](https://docs.docker.com/compose/)

---

**√öltima Actualizaci√≥n:** Octubre 27, 2025  
**Estado:** ‚úÖ Resuelto  
**Reportado por:** Sistema de Monitoreo  
**Solucionado por:** Equipo de Desarrollo

