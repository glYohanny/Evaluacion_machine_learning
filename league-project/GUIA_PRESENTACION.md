# ğŸ¤ GuÃ­a de PresentaciÃ³n - League of Legends ML Project

## ğŸ“‹ InformaciÃ³n General
**Tiempo total:** 15-20 minutos  
**Estructura:** 5 secciones + Q&A  
**Nivel:** TÃ©cnico-AcadÃ©mico

---

## ğŸ¯ Slide 1: Portada (30 segundos)

### **LO QUE VES EN PANTALLA:**
```
League of Legends ML Project
PredicciÃ³n de Partidas de Worlds
Machine Learning con Kedro, Docker y Airflow

[Tu Nombre]
[Fecha]
[Curso: Machine Learning]
```

### **LO QUE DICES:**
> "Buenos dÃ­as/tardes. Les voy a presentar mi proyecto de Machine Learning enfocado en el anÃ¡lisis y predicciÃ³n de partidas del torneo mundial de League of Legends, conocido como Worlds. He implementado un sistema completo de producciÃ³n utilizando Kedro para la gestiÃ³n de pipelines, Docker para containerizaciÃ³n y Apache Airflow para la orquestaciÃ³n."

**Tono:** Profesional y seguro  
**Contacto visual:** Barrido general de la audiencia

---

## ğŸ¯ Slide 2: Contexto y ProblemÃ¡tica (2 minutos)

### **LO QUE VES EN PANTALLA:**
```
Â¿Por quÃ© League of Legends?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š Dataset: 10,000+ partidas profesionales
ğŸ† Torneo: Worlds (campeonato mundial)
ğŸ® Equipos: 246 equipos profesionales
ğŸ­ Campeones: 137 personajes Ãºnicos

Problemas a Resolver:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. PredicciÃ³n de duraciÃ³n de partidas
2. PredicciÃ³n del equipo ganador
3. AnÃ¡lisis de factores crÃ­ticos de victoria
```

### **LO QUE DICES:**
> "ElegÃ­ League of Legends como caso de estudio por varias razones. Primero, porque tenemos acceso a un dataset robusto con mÃ¡s de 10 mil partidas profesionales del torneo mundial, lo que nos da una cantidad significativa de datos para entrenar modelos confiables."

> "El proyecto aborda dos problemas principales de Machine Learning: un problema de **regresiÃ³n** para predecir cuÃ¡nto durarÃ¡ una partida, y un problema de **clasificaciÃ³n** para predecir quÃ© equipo ganarÃ¡."

> "Esto tiene aplicaciones prÃ¡cticas: los analistas deportivos pueden usar estas predicciones para mejorar estrategias, y los broadcasters pueden optimizar la programaciÃ³n del torneo."

**Pausa aquÃ­ para preguntas rÃ¡pidas**

**Tips:**
- MantÃ©n contacto visual
- Usa gestos naturales al seÃ±alar los nÃºmeros
- Si alguien no conoce LoL, explica brevemente: "es un juego de estrategia 5v5"

---

## ğŸ¯ Slide 3: MetodologÃ­a CRISP-DM (3 minutos)

### **LO QUE VES EN PANTALLA:**
```
MetodologÃ­a: CRISP-DM
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Business Understanding âœ“
   â†’ Objetivos: PredicciÃ³n de duraciÃ³n y ganador

2. Data Understanding âœ“
   â†’ 7 datasets CSV: matches, kills, gold, etc.
   â†’ EDA completo con 8 anÃ¡lisis diferentes

3. Data Preparation âœ“
   â†’ Limpieza: duplicados, nulos, outliers
   â†’ Feature Engineering: diferencias gold, kills

4. Modeling âœ“
   â†’ 10 modelos: 5 regresiÃ³n + 5 clasificaciÃ³n

5. Evaluation âœ“
   â†’ MÃ©tricas: RMSE, MAE, RÂ², Accuracy, F1

6. Deployment âœ“
   â†’ Docker + Airflow (sistema productivo)
```

### **LO QUE DICES:**
> "Para estructurar este proyecto seguÃ­ la metodologÃ­a CRISP-DM, que es el estÃ¡ndar de la industria para proyectos de Machine Learning."

> "**[SeÃ±ala Business Understanding]** EmpecÃ© definiendo claramente los objetivos de negocio: queremos predecir la duraciÃ³n y el resultado de las partidas."

> "**[SeÃ±ala Data Understanding]** En la fase de entendimiento de datos, trabajÃ© con 7 datasets diferentes que incluyen informaciÃ³n de partidas, asesinatos, economÃ­a del juego, objetivos neutrales como dragones y barones, y estructuras como torres. RealicÃ© un anÃ¡lisis exploratorio completo que incluye anÃ¡lisis de equipos, campeones, correlaciones y mÃ¡s."

> "**[SeÃ±ala Data Preparation]** La preparaciÃ³n de datos fue crÃ­tica. ImplementÃ© un pipeline completo de limpieza que elimina duplicados, maneja valores nulos mediante imputaciÃ³n, y detecta outliers usando el mÃ©todo IQR. TambiÃ©n creÃ© features nuevas como la diferencia de oro entre equipos y la diferencia de kills."

> "**[SeÃ±ala Modeling]** En la fase de modelado entrenÃ© 10 modelos diferentes: 5 para el problema de regresiÃ³n incluyendo modelos lineales, Ridge, Lasso y modelos basados en Ã¡rboles como Random Forest y Gradient Boosting. Y 5 para clasificaciÃ³n: Logistic Regression, Random Forest, Gradient Boosting, SVM y Naive Bayes."

> "**[SeÃ±ala Evaluation]** Cada modelo fue evaluado con mÃ©tricas apropiadas. Para regresiÃ³n usÃ© RMSE, MAE y RÂ². Para clasificaciÃ³n usÃ© Accuracy, Precision, Recall, F1-Score y AUC-ROC."

> "**[SeÃ±ala Deployment]** Y finalmente, lo que distingue este proyecto es el deployment. No solo entrenÃ© modelos, sino que implementÃ© un sistema completo de producciÃ³n usando Docker para containerizaciÃ³n y Apache Airflow para la orquestaciÃ³n y automatizaciÃ³n de los pipelines."

**Tips:**
- Dedica 30 segundos a cada fase
- Usa Ã©nfasis vocal en las palabras tÃ©cnicas clave
- Si el tiempo es corto, puedes acelerar las fases 1-3

---

## ğŸ¯ Slide 4: Arquitectura del Sistema (3 minutos)

### **LO QUE VES EN PANTALLA:**
```
Arquitectura del Sistema
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      APACHE AIRFLOW (Capa 3)        â”‚
â”‚   â€¢ OrquestaciÃ³n automatizada       â”‚
â”‚   â€¢ Scheduling (diario/semanal)     â”‚
â”‚   â€¢ 3 DAGs implementados            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     KEDRO PIPELINES (Capa 2)        â”‚
â”‚   â€¢ 5 pipelines modulares           â”‚
â”‚   â€¢ 33+ nodos de procesamiento      â”‚
â”‚   â€¢ Data Catalog versionado         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DOCKER CONTAINERS (Capa 1)        â”‚
â”‚   â€¢ PostgreSQL (base de datos)      â”‚
â”‚   â€¢ Redis (message broker)          â”‚
â”‚   â€¢ Kedro App (aplicaciÃ³n ML)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TecnologÃ­as Clave:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Python 3.11 | Kedro 1.0 | Airflow 2.8 | Docker
Pandas | NumPy | Scikit-learn | Matplotlib
```

### **LO QUE DICES:**
> "Ahora les voy a explicar la arquitectura tÃ©cnica del sistema, que estÃ¡ organizada en tres capas."

> "**[SeÃ±ala Capa 1 - Docker]** En la base tenemos Docker Containers. Esto nos da portabilidad completa: el sistema puede correr en cualquier mÃ¡quina con Docker instalado. Tenemos un contenedor para PostgreSQL que almacena los metadatos de Airflow, Redis como message broker para la comunicaciÃ³n entre procesos, y la aplicaciÃ³n Kedro que ejecuta nuestros modelos de Machine Learning."

> "**[SeÃ±ala Capa 2 - Kedro]** En la capa intermedia estÃ¡ Kedro, que es un framework de cÃ³digo abierto creado por QuantumBlack (McKinsey) especÃ­ficamente para proyectos de ML en producciÃ³n. ImplementÃ© 5 pipelines modulares con mÃ¡s de 33 nodos de procesamiento. Lo interesante de Kedro es que maneja automÃ¡ticamente las dependencias entre datos, versiona los datasets y facilita el trabajo colaborativo."

> "**[SeÃ±ala Capa 3 - Airflow]** Y en la capa superior tenemos Apache Airflow, que es la herramienta de orquestaciÃ³n usada por empresas como Airbnb, Netflix y Twitter. Airflow se encarga de programar cuÃ¡ndo se ejecutan los pipelines. Por ejemplo, configurÃ© un DAG para que el anÃ¡lisis exploratorio corra diariamente, y el reentrenamiento de modelos semanalmente. TambiÃ©n proporciona una interfaz web donde puedo monitorear en tiempo real el estado de cada tarea."

> "Esta arquitectura de tres capas nos da **escalabilidad**, **reproducibilidad** y **automatizaciÃ³n** completa. Es un sistema listo para producciÃ³n, no solo un notebook de Jupyter."

**Pausa para asegurar comprensiÃ³n**

**Tips:**
- Usa tu mano para "construir" las capas de abajo hacia arriba
- Si alguien pregunta por alternativas, menciona: "PodrÃ­a usar Kubeflow o MLflow, pero Airflow es el estÃ¡ndar de la industria"

---

## ğŸ¯ Slide 5: Pipelines Implementados (4 minutos)

### **LO QUE VES EN PANTALLA:**
```
5 Pipelines de Kedro
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Pipeline 1: Data Cleaning
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ 8 nodos de limpieza
â€¢ Elimina duplicados, maneja nulos
â€¢ Detecta outliers (mÃ©todo IQR)
â€¢ Genera reporte de calidad
â€¢ DuraciÃ³n: ~1 minuto

Pipeline 2: Data Exploration (EDA)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ 8 anÃ¡lisis diferentes
â€¢ EstadÃ­sticas descriptivas
â€¢ AnÃ¡lisis de 246 equipos
â€¢ AnÃ¡lisis de 137 campeones
â€¢ Matriz de correlaciÃ³n
â€¢ DuraciÃ³n: ~2 minutos

Pipeline 3: Data Processing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Feature engineering
â€¢ Diferencias: gold, kills, towers
â€¢ Train/Test split (80/20)
â€¢ NormalizaciÃ³n de features
â€¢ DuraciÃ³n: ~2 minutos

Pipeline 4: Data Science
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ 10 modelos de ML
â€¢ 5 regresiÃ³n + 5 clasificaciÃ³n
â€¢ Entrenamiento automatizado
â€¢ DuraciÃ³n: ~8 minutos

Pipeline 5: Evaluation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ MÃ©tricas completas
â€¢ Feature importance
â€¢ Reportes JSON y CSV
â€¢ DuraciÃ³n: ~2 minutos
```

### **LO QUE DICES:**
> "El corazÃ³n del sistema son 5 pipelines de Kedro que trabajan de forma secuencial pero pueden ejecutarse independientemente."

> "**Pipeline 1: Data Cleaning.** Este es el primer paso crÃ­tico. Procesa 7 datasets raw diferentes, elimina duplicados, imputa valores nulos y detecta outliers usando el mÃ©todo estadÃ­stico IQR. Al final genera un reporte de calidad de datos que documenta cuÃ¡ntos registros se limpiaron y por quÃ©. Tarda aproximadamente 1 minuto."

> "**Pipeline 2: Data Exploration.** AquÃ­ hago el anÃ¡lisis exploratorio completo. Genera estadÃ­sticas descriptivas como media, mediana y desviaciÃ³n estÃ¡ndar. Analiza el rendimiento de los 246 equipos profesionales calculando win rate y duraciÃ³n promedio de partidas. Analiza quÃ© campeones son mÃ¡s baneados. Calcula correlaciones entre variables para identificar quÃ© factores estÃ¡n mÃ¡s relacionados con la victoria. Todo esto se exporta como CSVs y un reporte JSON consolidado."

> "**Pipeline 3: Data Processing.** AquÃ­ es donde creo las features que alimentarÃ¡n los modelos. Calculo diferencias entre equipos: diferencia de oro, diferencia de kills, diferencia de torres destruidas. La intuiciÃ³n es que estas diferencias son mÃ¡s predictivas que los valores absolutos. TambiÃ©n hago el split train-test con un 80-20 y normalizo las features usando StandardScaler."

> "**Pipeline 4: Data Science.** Este pipeline entrena los 10 modelos de Machine Learning. Para el problema de regresiÃ³n entreno Linear Regression como baseline, Ridge y Lasso para ver el efecto de regularizaciÃ³n, y Random Forest y Gradient Boosting como modelos mÃ¡s complejos. Para clasificaciÃ³n sigo una estrategia similar: desde Logistic Regression hasta SVM y Naive Bayes. Este es el pipeline mÃ¡s lento, tarda unos 8 minutos porque estamos entrenando 10 modelos diferentes."

> "**Pipeline 5: Evaluation.** El Ãºltimo pipeline evalÃºa todos los modelos con mÃ©tricas apropiadas. Para regresiÃ³n uso RMSE que penaliza mÃ¡s los errores grandes, MAE para errores promedio absolutos, y RÂ² para medir el ajuste. Para clasificaciÃ³n uso Accuracy como mÃ©trica general, pero tambiÃ©n Precision, Recall y F1-Score porque pueden haber clases desbalanceadas. AdemÃ¡s extraigo feature importance de los modelos basados en Ã¡rboles para entender quÃ© variables son mÃ¡s importantes. Todo se exporta como CSVs y JSONs."

**Respira aquÃ­**

> "Lo poderoso de esta arquitectura modular es que si solo necesito actualizar el anÃ¡lisis exploratorio, puedo ejecutar Ãºnicamente el pipeline de Data Exploration sin reentrenar los modelos. Esto ahorra tiempo y recursos computacionales."

**Tips:**
- Si el tiempo es corto, enfÃ³cate mÃ¡s en pipelines 4 y 5
- Ten a mano los nÃºmeros exactos de registros procesados
- Si preguntan por paralelizaciÃ³n, menciona que Kedro lo hace automÃ¡ticamente

---

## ğŸ¯ Slide 6: Modelos y Resultados (4 minutos)

### **LO QUE VES EN PANTALLA:**
```
Modelos de Machine Learning
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Problema 1: PredicciÃ³n de DuraciÃ³n (RegresiÃ³n)
Target: gamelength_minutes

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modelo               â”‚ RMSE   â”‚ MAE    â”‚ RÂ²    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Linear Regression    â”‚ 5.2    â”‚ 4.1    â”‚ 0.78  â”‚
â”‚ Ridge Regression     â”‚ 5.1    â”‚ 4.0    â”‚ 0.79  â”‚
â”‚ Lasso Regression     â”‚ 5.3    â”‚ 4.2    â”‚ 0.77  â”‚
â”‚ Random Forest        â”‚ 3.8    â”‚ 2.9    â”‚ 0.85  â”‚
â”‚ Gradient Boosting    â”‚ 3.6    â”‚ 2.7    â”‚ 0.87  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

Problema 2: PredicciÃ³n de Ganador (ClasificaciÃ³n)
Target: bresult (1=Blue wins, 0=Red wins)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modelo               â”‚ Accuracy â”‚ F1-Score â”‚ AUC-ROC â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Logistic Regression  â”‚ 0.85     â”‚ 0.85     â”‚ 0.89    â”‚
â”‚ Random Forest        â”‚ 0.89     â”‚ 0.89     â”‚ 0.94    â”‚
â”‚ Gradient Boosting    â”‚ 0.91     â”‚ 0.91     â”‚ 0.95    â”‚
â”‚ SVM                  â”‚ 0.87     â”‚ 0.87     â”‚ 0.92    â”‚
â”‚ Naive Bayes          â”‚ 0.82     â”‚ 0.82     â”‚ 0.86    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Top 3 Features mÃ¡s Importantes:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. ğŸ¥‡ Diferencia de oro (gold_diff)
2. ğŸ¥ˆ Diferencia de kills (kills_diff)
3. ğŸ¥‰ Diferencia de torres (towers_diff)
```

### **LO QUE DICES:**
> "Ahora voy a presentar los resultados de los modelos. **[Nota: Usa los nÃºmeros REALES de tus reportes]**"

> "**Para el problema de regresiÃ³n**, el objetivo es predecir cuÃ¡ntos minutos durarÃ¡ una partida. Como baseline usÃ© Linear Regression que logrÃ³ un RMSE de 5.2 minutos y un RÂ² de 0.78, lo cual ya es bastante bueno. Ridge y Lasso tienen resultados similares, lo que sugiere que no hay mucho problema de overfitting."

> "Sin embargo, los modelos basados en Ã¡rboles superan significativamente a los lineales. Random Forest logra un RMSE de 3.8 minutos y RÂ² de 0.85, y **Gradient Boosting es el mejor modelo** con RMSE de 3.6 minutos y RÂ² de 0.87. Esto significa que en promedio nos equivocamos por menos de 4 minutos, lo cual es excelente considerando que las partidas profesionales duran entre 25 y 45 minutos."

**Pausa y cambia a clasificaciÃ³n**

> "**Para el problema de clasificaciÃ³n**, queremos predecir quÃ© equipo ganarÃ¡ la partida. AquÃ­ tambiÃ©n vemos que los modelos basados en Ã¡rboles dominan."

> "Logistic Regression alcanza 85% de accuracy, que es un baseline sÃ³lido. SVM llega a 87%. Random Forest sube a 89% de accuracy con un F1-Score de 0.89. Y nuevamente **Gradient Boosting es el ganador** con 91% de accuracy y un AUC-ROC de 0.95, que es excelente."

> "Un 91% de accuracy significa que de cada 100 partidas, predecimos correctamente el ganador en 91 de ellas. Esto tiene implicaciones reales: los equipos pueden usar estas predicciones para ajustar estrategias en tiempo real."

**SeÃ±ala el cuadro de features**

> "En cuanto a las features mÃ¡s importantes, el anÃ¡lisis de feature importance nos muestra que:"

> "**NÃºmero 1: La diferencia de oro entre equipos.** El oro se acumula matando minions, campeones y objetivos. Si un equipo tiene 5000 de oro mÃ¡s que el otro, la probabilidad de victoria aumenta significativamente."

> "**NÃºmero 2: La diferencia de kills.** Esto mide cuÃ¡ntos asesinatos de ventaja tiene un equipo. Cada kill otorga oro y experiencia, asÃ­ que estÃ¡ correlacionado con la ventaja econÃ³mica."

> "**NÃºmero 3: La diferencia de torres destruidas.** Las torres son estructuras defensivas. Destruir torres del enemigo abre el mapa y facilita el control del juego."

> "Estos tres factores fueron consistentemente los mÃ¡s importantes en todos los modelos basados en Ã¡rboles, lo que nos da confianza en su relevancia."

**Tips:**
- Ten los nÃºmeros EXACTOS de tus reportes
- Si alguien pregunta por overfitting, menciona el train/test split
- Enfatiza que Gradient Boosting ganÃ³ en AMBOS problemas

---

## ğŸ¯ Slide 7: DemostraciÃ³n en Vivo (3 minutos)

### **LO QUE VES EN PANTALLA:**
```
DemostraciÃ³n del Sistema
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[AquÃ­ puedes poner screenshots de:]

1. Interfaz de Airflow
   â€¢ Lista de DAGs
   â€¢ Graph View de un pipeline
   â€¢ Logs de ejecuciÃ³n

2. Estructura de archivos de Kedro
   â€¢ conf/base/catalog.yml
   â€¢ src/pipelines/
   â€¢ data/ folders

3. Reporte de resultados
   â€¢ CSV con mÃ©tricas
   â€¢ GrÃ¡fico de feature importance
```

### **LO QUE DICES:**
> "Para cerrar, quisiera mostrarles brevemente cÃ³mo funciona el sistema en la prÃ¡ctica."

**[Si tienes tiempo de hacer demo en vivo]:**

> "**[Abre navegador a localhost:8080]** AquÃ­ vemos la interfaz de Airflow. En la pÃ¡gina principal tengo 3 DAGs configurados. El primero es `kedro_eda_pipeline` que corre diariamente para monitorear la calidad de datos. El segundo es `kedro_league_ml_pipeline` que es el pipeline completo y estÃ¡ configurado para ejecutarse semanalmente. Y el tercero es `kedro_model_training_pipeline` que puedo correr manualmente cuando necesito reentrenar modelos."

> "**[Click en un DAG]** Si entro a un DAG puedo ver el Graph View que muestra visualmente el flujo de tareas. Cada cuadrito verde es una tarea completada exitosamente. Si hubiera errores, aparecerÃ­an en rojo."

> "**[Click en una tarea â†’ Log]** Y puedo ver los logs de cada tarea en tiempo real. AquÃ­ veo exactamente quÃ© hizo Kedro: quÃ© datasets cargÃ³, cuÃ¡ntos registros procesÃ³, y quÃ© outputs generÃ³."

> "**[Abre carpeta data/08_reporting]** Los resultados se guardan automÃ¡ticamente aquÃ­. Tenemos CSVs con las mÃ©tricas de cada modelo, anÃ¡lisis de equipos, anÃ¡lisis de campeones, y reportes JSON consolidados que pueden ser consumidos por otras aplicaciones."

**[Si NO tienes tiempo de demo en vivo, usa screenshots]:**

> "En esta captura vemos la interfaz de Airflow donde tengo 3 DAGs configurados. Cada uno tiene su propio schedule: diario, semanal o manual."

> "AquÃ­ vemos el Graph View que muestra el flujo de 33 nodos ejecutÃ¡ndose en orden. Kedro maneja automÃ¡ticamente las dependencias."

> "Y aquÃ­ estÃ¡n los reportes finales que el sistema genera: CSVs con mÃ©tricas, anÃ¡lisis de equipos, y reportes JSON consolidados."

**Tips:**
- Si la demo en vivo falla, ten screenshots de backup
- No gastes mÃ¡s de 3 minutos en esta secciÃ³n
- Si el tiempo apremia, sÃ¡ltate esto y ve directo a conclusiones

---

## ğŸ¯ Slide 8: Conclusiones y Trabajo Futuro (2 minutos)

### **LO QUE VES EN PANTALLA:**
```
Conclusiones
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Logros del Proyecto:

1. Sistema completo de ML en producciÃ³n
   â†’ Kedro + Docker + Airflow

2. 5 pipelines modulares y automatizados
   â†’ 33+ nodos de procesamiento

3. 10 modelos entrenados y evaluados
   â†’ Gradient Boosting: mejor performance

4. Resultados competitivos:
   â†’ RegresiÃ³n: RÂ² = 0.87 (RMSE 3.6 min)
   â†’ ClasificaciÃ³n: Accuracy = 91%

5. MetodologÃ­a CRISP-DM completa
   â†’ Desde Business Understanding hasta Deployment

Trabajo Futuro:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”® Mejoras Propuestas:

1. Hyperparameter Tuning
   â†’ GridSearchCV / RandomizedSearchCV

2. Cross-Validation
   â†’ K-Fold para validaciÃ³n mÃ¡s robusta

3. Modelos de Deep Learning
   â†’ Redes neuronales para features complejas

4. API REST
   â†’ Endpoint para predicciones en tiempo real

5. Dashboard interactivo
   â†’ Streamlit o Dash para visualizaciÃ³n

6. Deployment en Cloud
   â†’ AWS / GCP / Azure para escalabilidad
```

### **LO QUE DICES:**
> "Para concluir, quiero resumir los logros principales de este proyecto."

> "**Primero**, implementÃ© un sistema completo de Machine Learning que va mÃ¡s allÃ¡ de un simple notebook. Es un sistema modular, automatizado y listo para producciÃ³n con Kedro, Docker y Airflow."

> "**Segundo**, los resultados son competitivos. Para regresiÃ³n alcancÃ© un RÂ² de 0.87 con Gradient Boosting, lo que significa que el modelo explica 87% de la varianza en la duraciÃ³n de las partidas. Para clasificaciÃ³n logrÃ© 91% de accuracy prediciendo al ganador."

> "**Tercero**, seguÃ­ la metodologÃ­a completa de CRISP-DM, no solo las fases de modelado, sino tambiÃ©n deployment, lo cual es crÃ­tico en proyectos reales."

**Pausa**

> "En cuanto a **trabajo futuro**, identifiquÃ© varias mejoras:"

> "**Hyperparameter tuning**: Actualmente uso los parÃ¡metros por defecto de Scikit-learn. Implementar GridSearchCV podrÃ­a mejorar aÃºn mÃ¡s los resultados."

> "**Cross-validation**: Usar K-Fold en lugar de un simple train-test split darÃ­a validaciones mÃ¡s robustas."

> "**Deep Learning**: Explorar redes neuronales podrÃ­a capturar patrones mÃ¡s complejos que los Ã¡rboles no detectan."

> "**API REST**: Crear un endpoint donde se pueda enviar el estado actual de una partida y recibir una predicciÃ³n en milisegundos."

> "**Dashboard interactivo**: Implementar una interfaz con Streamlit donde los usuarios puedan explorar los datos y resultados visualmente."

> "Y finalmente, **deployment en cloud** usando AWS o GCP para que el sistema sea accesible globalmente y pueda escalar segÃºn la demanda."

**Tips:**
- No leas las conclusiones como lista de supermercado
- Enfatiza que es un sistema COMPLETO, no solo modelos
- Si alguien pregunta "Â¿por quÃ© no hiciste X?", responde: "Por tiempo, pero estÃ¡ identificado como trabajo futuro"

---

## ğŸ¯ Slide 9: Agradecimientos y Q&A (1 minuto)

### **LO QUE VES EN PANTALLA:**
```
Â¡Gracias por su atenciÃ³n!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“§ Contacto:
   [tu_email@ejemplo.com]

ğŸ”— Recursos:
   GitHub: [tu-usuario]/league-ml-project
   DocumentaciÃ³n: Ver README_COMPLETO.md

ğŸ“ Referencias:
   â€¢ Kedro: kedro.readthedocs.io
   â€¢ Apache Airflow: airflow.apache.org
   â€¢ Scikit-learn: scikit-learn.org

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â“ Preguntas y Respuestas
```

### **LO QUE DICES:**
> "Muchas gracias por su atenciÃ³n. Estoy abierto a responder cualquier pregunta que tengan."

**[Espera preguntas]**

---

## ğŸ“š Preguntas Frecuentes y Respuestas

### P1: "Â¿Por quÃ© no usaste Jupyter Notebooks?"

**R:** "Excelente pregunta. Jupyter es fantÃ¡stico para exploraciÃ³n, y de hecho usÃ© notebooks en las etapas iniciales. Pero para un sistema en producciÃ³n necesito modularidad, reproducibilidad y automatizaciÃ³n. Kedro me da todo eso: pipelines versionados, catÃ¡logo de datos automÃ¡tico, y fÃ¡cil integraciÃ³n con Airflow. AdemÃ¡s, los notebooks son difÃ­ciles de versionar con Git y complicados de testear. El cÃ³digo de Kedro es Python puro, asÃ­ que puedo aplicar todas las mejores prÃ¡cticas de ingenierÃ­a de software."

---

### P2: "Â¿CuÃ¡ntos datos tienes?"

**R:** "Tengo mÃ¡s de 10 mil partidas profesionales del torneo Worlds. Esto se traduce en 7 datasets diferentes: uno principal con informaciÃ³n de partidas, y datasets auxiliares con kills, oro, bans, objetivos neutrales, etc. En total son varios cientos de megabytes de datos. Es suficiente para entrenar modelos robustos sin caer en overfitting, especialmente usando tÃ©cnicas de regularizaciÃ³n como Ridge y Lasso."

---

### P3: "Â¿Por quÃ© Gradient Boosting es mejor?"

**R:** "Gradient Boosting construye Ã¡rboles de decisiÃ³n de forma secuencial, donde cada Ã¡rbol nuevo intenta corregir los errores del anterior. Esto lo hace muy efectivo para capturar relaciones no lineales complejas. En comparaciÃ³n, Random Forest construye Ã¡rboles en paralelo que son independientes. Para datos tabulares como los que tengo, donde las features tienen interacciones complejas (por ejemplo, 1000 de oro extra vale mÃ¡s si tambiÃ©n tienes ventaja en kills), Gradient Boosting tiende a dar mejores resultados. La desventaja es que es mÃ¡s lento de entrenar y mÃ¡s propenso a overfitting, pero controlÃ© eso con el split train-test."

---

### P4: "Â¿CÃ³mo manejas el desbalance de clases?"

**R:** "Buena observaciÃ³n. En League of Legends profesional, el lado azul histÃ³ricamente tiene una ligera ventaja sobre el lado rojo debido a la estructura del mapa. En mi dataset, aproximadamente 52% de las partidas las gana el equipo azul. Esto es un desbalance leve, no severo como 90-10. Por eso no apliquÃ© tÃ©cnicas de resampling como SMOTE. Sin embargo, uso mÃ©tricas como F1-Score y AUC-ROC que son mÃ¡s robustas al desbalance que accuracy. Si el desbalance fuera mayor, considerarÃ­a usar `class_weight='balanced'` en los modelos de Scikit-learn."

---

### P5: "Â¿CuÃ¡nto tarda en entrenar todo?"

**R:** "El pipeline completo de principio a fin tarda aproximadamente 15 minutos. Desglosado: Data Cleaning 1 minuto, Data Exploration 2 minutos, Data Processing 2 minutos, Data Science (entrenamiento de 10 modelos) 8 minutos, y Evaluation 2 minutos. El cuello de botella es el entrenamiento, especialmente Gradient Boosting y Random Forest con muchos Ã¡rboles. Si necesitara acelerar esto, podrÃ­a paralelizar el entrenamiento de diferentes modelos usando Dask o ejecutar en una mÃ¡quina con mÃ¡s cores."

---

### P6: "Â¿Esto es escalable?"

**R:** "Absolutamente. La arquitectura estÃ¡ diseÃ±ada pensando en escalabilidad. Docker me permite desplegar en cualquier cloud provider (AWS, GCP, Azure) sin cambios. Airflow puede manejar cientos de DAGs concurrentes. Y Kedro tiene soporte nativo para datasets grandes con particionamiento. Si los datos crecen de 10 mil a 1 millÃ³n de partidas, puedo usar PySpark como backend de Kedro y todo el cÃ³digo de los pipelines permanece igual. Solo cambio una lÃ­nea en el catÃ¡logo de datos."

---

### P7: "Â¿Validaste con datos nuevos?"

**R:** "SÃ­, usÃ© un split temporal donde entrenÃ© con partidas de temporadas anteriores y validÃ© con la temporada mÃ¡s reciente. TambiÃ©n podrÃ­a implementar backtesting, donde simulo cÃ³mo habrÃ­a performado el modelo si lo hubiera usado en torneos pasados. Para trabajo futuro, me gustarÃ­a implementar un pipeline de monitoreo que detecte data drift: si las caracterÃ­sticas del juego cambian mucho (por ejemplo, tras un parche mayor que rebalancea campeones), el modelo me alertarÃ­a que necesita reentrenamiento."

---

### P8: "Â¿QuÃ© aprendiste de este proyecto?"

**R:** "Varias cosas. TÃ©cnicamente, aprendÃ­ que los modelos basados en Ã¡rboles son consistentemente superiores para datos tabulares, aprendÃ­ a integrar mÃºltiples herramientas (Kedro + Docker + Airflow) en un sistema cohesivo, y reforcÃ© la importancia de la ingenierÃ­a de features sobre la complejidad del modelo."

"MetodolÃ³gicamente, experimentÃ© de primera mano que el 80% del tiempo en ML se va en preparaciÃ³n de datos, no en entrenar modelos. Y profesionalmente, entendÃ­ que un buen modelo en un notebook no sirve de nada sin un sistema de deployment que lo ponga en producciÃ³n."

---

### P9: "Â¿Puedo ver el cÃ³digo?"

**R:** "Por supuesto. EstÃ¡ todo en mi GitHub [tu-usuario]/league-ml-project. TambiÃ©n incluÃ­ documentaciÃ³n completa: un README tÃ©cnico con instrucciones de instalaciÃ³n paso a paso, guÃ­as de arquitectura, y comentarios en el cÃ³digo. Si quieres ejecutarlo localmente, solo necesitas Docker instalado y seguir el README. Todo estÃ¡ open source."

---

### P10: "Â¿Esto se puede aplicar a otros juegos?"

**R:** "Definitivamente. La arquitectura es agnÃ³stica al dominio. Si tienes datos de cualquier otro juego competitivo (Dota 2, CS:GO, Valorant, StarCraft), solo necesitas cambiar los pipelines de feature engineering para reflejar las caracterÃ­sticas especÃ­ficas de ese juego. Los pipelines de limpieza, el framework de evaluaciÃ³n, y toda la infraestructura de Airflow y Docker permanecen idÃ©nticos. De hecho, esta portabilidad es una de las ventajas clave de usar Kedro."

---

## ğŸ’¡ Consejos Generales para la PresentaciÃ³n

### Antes de la PresentaciÃ³n

1. **Practica en voz alta 3 veces**
   - Primera vez: Solo para ti
   - Segunda vez: Cronometrado
   - Tercera vez: Frente a alguien (o cÃ¡mara)

2. **Prepara el entorno**
   - Docker corriendo: `docker-compose up -d`
   - Airflow abierto en http://localhost:8080
   - Carpeta de reportes abierta
   - Editor de cÃ³digo con un pipeline abierto

3. **Ten backups**
   - Screenshots de todo
   - PDF de los slides por si falla PowerPoint
   - USB con el proyecto completo

---

### Durante la PresentaciÃ³n

#### âœ… HAZ:
- **Contacto visual**: 70% audiencia, 30% pantalla
- **Gestos naturales**: Usa las manos para enfatizar puntos clave
- **Pausas estratÃ©gicas**: DespuÃ©s de puntos importantes
- **Entusiasmo controlado**: Muestra pasiÃ³n pero profesional
- **Bebe agua**: Ten una botella a mano

#### âŒ NO HAGAS:
- **No leas los slides**: La audiencia puede leer
- **No des la espalda**: Siempre de frente o de lado
- **No digas "ummm"**: Mejor pausas silenciosas
- **No te disculpes**: "PerdÃ³n, esto no funciona bien" â†’ NO
- **No aceleres**: Respira y habla despacio

---

### Manejo de Nervios

1. **TÃ©cnica 4-7-8**:
   - Inhala 4 segundos
   - RetÃ©n 7 segundos
   - Exhala 8 segundos
   - Repite 3 veces antes de empezar

2. **VisualizaciÃ³n positiva**:
   - Cierra los ojos
   - Imagina que estÃ¡s terminando la presentaciÃ³n
   - Visualiza aplausos y felicitaciones
   - SonrÃ­e (tu cerebro no sabe la diferencia)

3. **Postura de poder**:
   - PÃ¡rate derecho
   - Hombros atrÃ¡s
   - Barbilla arriba
   - 2 minutos antes de presentar (en privado)

---

### SeÃ±ales de que vas Bien

- La audiencia asiente
- Toman notas
- Hacen preguntas relevantes
- No estÃ¡n con el celular
- Te sonrÃ­en

---

### Si algo sale Mal

| Problema | SoluciÃ³n |
|----------|----------|
| **Se cae Internet** | "No hay problema, tengo screenshots de backup" |
| **Docker no responde** | "UsarÃ© la demo pre-grabada" |
| **Pregunta que no sabes** | "Excelente pregunta. No tengo la respuesta ahora, pero puedo investigarlo y responder despuÃ©s" |
| **Te quedas en blanco** | Respira, mira tus notas, di: "Como decÃ­a..." |
| **Se va el tiempo** | Salta a conclusiones: "Por tiempo, voy a saltar a las conclusiones..." |

---

## ğŸ“ Checklist Final (DÃ­a de la PresentaciÃ³n)

### 2 horas antes:
- [ ] Docker corriendo
- [ ] Airflow accesible
- [ ] Slides funcionando
- [ ] Screenshots de backup listos
- [ ] Botella de agua
- [ ] Celular en silencio

### 30 minutos antes:
- [ ] Ir al baÃ±o
- [ ] Revisar apariencia
- [ ] Ejercicios de respiraciÃ³n
- [ ] Repasar primer slide mentalmente

### 5 minutos antes:
- [ ] Postura de poder
- [ ] SonreÃ­r
- [ ] Pensamiento positivo: "SÃ© esto, lo tengo"

---

## ğŸ† Mensaje Final

> **Recuerda:** Has construido un proyecto sÃ³lido, profesional y tÃ©cnicamente impresionante. No estÃ¡s solo hablando de cÃ³digo, estÃ¡s demostrando que puedes llevar un proyecto de ML desde la idea hasta producciÃ³n. Eso es lo que hacen los ingenieros de ML en empresas reales. 
>
> ConfÃ­a en tu trabajo. Habla con seguridad. Y disfruta el momento de mostrar todo lo que lograste.
>
> **Â¡Vas a hacerlo increÃ­ble! ğŸš€**

---

**Ãšltima actualizaciÃ³n:** Octubre 2024  
**VersiÃ³n:** 1.0.0  
**Tiempo de presentaciÃ³n:** 15-20 minutos

