# ğŸ”„ GuÃ­a de Pipelines de Limpieza y AnÃ¡lisis

## ğŸ“‹ DescripciÃ³n

Esta guÃ­a explica cÃ³mo usar los pipelines de **limpieza** y **anÃ¡lisis exploratorio** para procesar los datos raw de League of Legends.

## ğŸ¯ Pipelines Disponibles

### 1. **data_cleaning** (Limpieza de Datos)
Limpia y prepara los datos raw para anÃ¡lisis.

### 2. **data_exploration** (AnÃ¡lisis Exploratorio)
Genera estadÃ­sticas, anÃ¡lisis y reportes de insights.

### 3. **eda** (Pipeline Combinado)
Ejecuta limpieza + exploraciÃ³n en secuencia.

---

## ğŸš€ Comandos de EjecuciÃ³n

### Ejecutar Pipeline de Limpieza

```bash
# Cambiar al directorio del proyecto
cd league-project

# Activar entorno virtual
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # macOS/Linux

# Ejecutar limpieza de datos
kedro run --pipeline data_cleaning

# O usar alias corto
kedro run --pipeline dc
```

### Ejecutar Pipeline de ExploraciÃ³n

```bash
# Ejecutar exploraciÃ³n de datos
kedro run --pipeline data_exploration

# O usar alias corto
kedro run --pipeline de
```

### Ejecutar Ambos Pipelines

```bash
# Ejecutar limpieza + exploraciÃ³n
kedro run --pipeline eda
```

### Ejecutar Todo el Proyecto

```bash
# Ejecutar pipeline completo (limpieza + exploraciÃ³n + procesamiento + modelos + evaluaciÃ³n)
kedro run
```

---

## ğŸ“Š Pipeline de Limpieza (data_cleaning)

### Â¿QuÃ© hace?

1. **Limpia LeagueofLegends.csv** (dataset principal)
   - Elimina duplicados
   - Imputa valores faltantes
   - Convierte tipos de datos
   - Elimina outliers extremos
   - Crea features bÃ¡sicas (KDA)

2. **Limpia matchinfo.csv**
   - Estandariza nombres de columnas
   - Convierte fechas a datetime
   - Extrae features temporales

3. **Limpia bans.csv**
   - Limpia nombres de campeones
   - Valida orden de bans
   - Elimina registros invÃ¡lidos

4. **Limpia gold.csv**
   - Valida valores positivos
   - Calcula diferencias de oro

5. **Limpia kills.csv**
   - Valida tiempos
   - Limpia nombres de jugadores

6. **Limpia monsters.csv**
   - Estandariza tipos de objetivos
   - Valida tiempos

7. **Limpia structures.csv**
   - Estandariza tipos de estructuras
   - Valida lanes

8. **Genera Reporte de Calidad**
   - MÃ©tricas de calidad por dataset
   - EstadÃ­sticas de limpieza

### Outputs

Todos los datos limpios se guardan en `data/02_intermediate/`:

- `main_clean.csv` - Dataset principal limpio
- `matchinfo_clean.csv` - InformaciÃ³n de partidos limpia
- `bans_clean.csv` - Bans limpios
- `gold_clean.csv` - EstadÃ­sticas de oro limpias
- `kills_clean.csv` - Kills limpios
- `monsters_clean.csv` - Objetivos limpios
- `structures_clean.csv` - Estructuras limpias

Reporte de calidad en `data/08_reporting/`:

- `data_quality_report_cleaning.csv` - Reporte de calidad

### Ejemplo de EjecuciÃ³n

```bash
(venv) C:\...\league-project> kedro run --pipeline data_cleaning

[10/27/25 12:00:00] INFO     Kedro project league_project
[10/27/25 12:00:01] INFO     Loading data from 'raw_main_data' (CSVDataset)...
[10/27/25 12:00:02] INFO     Running node: clean_main_dataset_node
[10/27/25 12:00:02] INFO     Iniciando limpieza del dataset principal: 10000 filas
[10/27/25 12:00:03] INFO     Eliminados 150 duplicados completos
[10/27/25 12:00:03] INFO     Valores faltantes: 500 â†’ 0
[10/27/25 12:00:04] INFO     Limpieza completada: 9850 filas finales
[10/27/25 12:00:04] INFO     Saving data to 'intermediate_main_data' (CSVDataset)...
...
[10/27/25 12:00:30] INFO     Pipeline execution completed successfully.
```

---

## ğŸ“ˆ Pipeline de ExploraciÃ³n (data_exploration)

### Â¿QuÃ© hace?

1. **EstadÃ­sticas Descriptivas**
   - Media, mediana, desviaciÃ³n estÃ¡ndar
   - AsimetrÃ­a, curtosis
   - Valores faltantes

2. **AnÃ¡lisis de Rendimiento de Equipos**
   - Win rate por equipo
   - EstadÃ­sticas promedio (kills, deaths, assists, gold)
   - KDA promedio

3. **AnÃ¡lisis de Bans de Campeones**
   - Campeones mÃ¡s baneados
   - Frecuencia y porcentaje de bans
   - Orden promedio de ban

4. **AnÃ¡lisis de Objetivos Neutrales**
   - Dragones, Baron, Herald capturados
   - Tiempo promedio de captura
   - Captura por equipo

5. **AnÃ¡lisis de Estructuras**
   - Torres e inhibidores destruidos
   - Tiempo promedio de destrucciÃ³n
   - DestrucciÃ³n por lane

6. **AnÃ¡lisis de Correlaciones**
   - Correlaciones entre variables numÃ©ricas
   - ClasificaciÃ³n por fuerza (fuerte, moderada, dÃ©bil)

7. **AnÃ¡lisis de DuraciÃ³n de Partidos**
   - EstadÃ­sticas de duraciÃ³n
   - CategorizaciÃ³n (corta, media, larga, muy larga)
   - DistribuciÃ³n de duraciones

8. **Reporte Completo de EDA**
   - Resumen de todos los anÃ¡lisis
   - Insights clave

### Outputs

Todos los anÃ¡lisis se guardan en `data/08_reporting/`:

- `descriptive_statistics.csv` - EstadÃ­sticas descriptivas
- `team_performance_analysis.csv` - Rendimiento de equipos
- `champion_bans_analysis.csv` - AnÃ¡lisis de bans
- `neutral_objectives_analysis.csv` - AnÃ¡lisis de objetivos
- `structures_analysis.csv` - AnÃ¡lisis de estructuras
- `correlations_analysis.csv` - AnÃ¡lisis de correlaciones
- `game_duration_analysis.csv` - AnÃ¡lisis de duraciÃ³n
- `eda_complete_report.json` - Reporte completo

### Ejemplo de EjecuciÃ³n

```bash
(venv) C:\...\league-project> kedro run --pipeline data_exploration

[10/27/25 12:05:00] INFO     Kedro project league_project
[10/27/25 12:05:01] INFO     Loading data from 'intermediate_main_data' (CSVDataset)...
[10/27/25 12:05:02] INFO     Running node: generate_descriptive_stats_node
[10/27/25 12:05:02] INFO     Generando estadÃ­sticas descriptivas
[10/27/25 12:05:03] INFO     EstadÃ­sticas generadas para 25 columnas
[10/27/25 12:05:03] INFO     Saving data to 'descriptive_statistics' (CSVDataset)...
...
[10/27/25 12:05:30] INFO     Analizando rendimiento de equipos
[10/27/25 12:05:31] INFO     AnÃ¡lisis completado para 20 equipos
...
[10/27/25 12:06:00] INFO     Pipeline execution completed successfully.
```

---

## ğŸ“‚ Estructura de Datos

### Antes de la Limpieza
```
data/01_raw/
â”œâ”€â”€ LeagueofLegends.csv    â† Dataset principal (puede tener duplicados, NaN)
â”œâ”€â”€ matchinfo.csv          â† Info de partidos (fechas sin formato)
â”œâ”€â”€ bans.csv              â† Bans (nombres sin limpiar)
â”œâ”€â”€ gold.csv              â† EstadÃ­sticas de oro
â”œâ”€â”€ kills.csv             â† InformaciÃ³n de kills
â”œâ”€â”€ monsters.csv          â† Objetivos neutrales
â””â”€â”€ structures.csv        â† Estructuras destruidas
```

### DespuÃ©s de la Limpieza
```
data/02_intermediate/
â”œâ”€â”€ main_clean.csv        â† Dataset principal limpio
â”œâ”€â”€ matchinfo_clean.csv   â† Info de partidos limpia
â”œâ”€â”€ bans_clean.csv        â† Bans limpios
â”œâ”€â”€ gold_clean.csv        â† Oro limpio
â”œâ”€â”€ kills_clean.csv       â† Kills limpios
â”œâ”€â”€ monsters_clean.csv    â† Objetivos limpios
â””â”€â”€ structures_clean.csv  â† Estructuras limpias
```

### DespuÃ©s de la ExploraciÃ³n
```
data/08_reporting/
â”œâ”€â”€ descriptive_statistics.csv
â”œâ”€â”€ team_performance_analysis.csv
â”œâ”€â”€ champion_bans_analysis.csv
â”œâ”€â”€ neutral_objectives_analysis.csv
â”œâ”€â”€ structures_analysis.csv
â”œâ”€â”€ correlations_analysis.csv
â”œâ”€â”€ game_duration_analysis.csv
â”œâ”€â”€ eda_complete_report.json
â””â”€â”€ data_quality_report_cleaning.csv
```

---

## ğŸ” Ver Resultados de los AnÃ¡lisis

### En Python

```python
import pandas as pd

# Cargar estadÃ­sticas descriptivas
stats = pd.read_csv('data/08_reporting/descriptive_statistics.csv')
print(stats.head())

# Cargar anÃ¡lisis de equipos
teams = pd.read_csv('data/08_reporting/team_performance_analysis.csv')
print(teams.sort_values('win_rate', ascending=False).head(10))

# Cargar anÃ¡lisis de bans
bans = pd.read_csv('data/08_reporting/champion_bans_analysis.csv')
print(bans.head(20))

# Cargar reporte completo
import json
with open('data/08_reporting/eda_complete_report.json', 'r') as f:
    report = json.load(f)
print(report)
```

### En Notebook

```python
# notebooks/analizar_resultados.py
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ConfiguraciÃ³n
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Cargar datos limpios
df_main = pd.read_csv('data/02_intermediate/main_clean.csv')
print(f"Datos limpios: {len(df_main)} filas")

# Cargar anÃ¡lisis
teams = pd.read_csv('data/08_reporting/team_performance_analysis.csv')
bans = pd.read_csv('data/08_reporting/champion_bans_analysis.csv')

# Visualizar top 10 equipos
plt.figure(figsize=(12, 6))
top_teams = teams.nlargest(10, 'win_rate')
plt.barh(top_teams['team'], top_teams['win_rate'])
plt.title('Top 10 Equipos por Win Rate')
plt.xlabel('Win Rate')
plt.tight_layout()
plt.savefig('top_teams.png')
plt.show()

# Visualizar top 20 bans
plt.figure(figsize=(12, 8))
top_bans = bans.head(20)
plt.barh(range(len(top_bans)), top_bans['ban_count'])
plt.yticks(range(len(top_bans)), top_bans['champion'])
plt.title('Top 20 Campeones MÃ¡s Baneados')
plt.xlabel('NÃºmero de Bans')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('top_bans.png')
plt.show()
```

---

## ğŸ› ï¸ Comandos Avanzados

### Ejecutar Solo un Nodo EspecÃ­fico

```bash
# Ejecutar solo la limpieza del dataset principal
kedro run --node clean_main_dataset_node

# Ejecutar solo el anÃ¡lisis de equipos
kedro run --node analyze_team_performance_node
```

### Ejecutar con Tags

```bash
# Ejecutar solo nodos de limpieza
kedro run --tag cleaning

# Ejecutar solo nodos de EDA
kedro run --tag eda

# Ejecutar solo nodos de reporting
kedro run --tag reporting
```

### Ejecutar desde un Nodo EspecÃ­fico

```bash
# Ejecutar desde el anÃ¡lisis de bans en adelante
kedro run --from-nodes analyze_champion_bans_node

# Ejecutar hasta el anÃ¡lisis de correlaciones
kedro run --to-nodes analyze_correlations_node
```

### Ejecutar con Logging Detallado

```bash
# Ejecutar con logging verbose
kedro run --pipeline data_cleaning --verbose

# Ver logs en tiempo real
Get-Content info.log -Wait  # Windows PowerShell
# tail -f info.log  # macOS/Linux
```

---

## ğŸ“Š Verificar que Todo Funciona

### Script de VerificaciÃ³n

```python
# verificar_pipelines.py
import os
import pandas as pd

def verificar_archivos():
    """Verifica que todos los archivos fueron generados."""
    
    archivos_esperados = [
        # Datos limpios
        'data/02_intermediate/main_clean.csv',
        'data/02_intermediate/matchinfo_clean.csv',
        'data/02_intermediate/bans_clean.csv',
        'data/02_intermediate/gold_clean.csv',
        'data/02_intermediate/kills_clean.csv',
        'data/02_intermediate/monsters_clean.csv',
        'data/02_intermediate/structures_clean.csv',
        
        # Reportes
        'data/08_reporting/data_quality_report_cleaning.csv',
        'data/08_reporting/descriptive_statistics.csv',
        'data/08_reporting/team_performance_analysis.csv',
        'data/08_reporting/champion_bans_analysis.csv',
        'data/08_reporting/neutral_objectives_analysis.csv',
        'data/08_reporting/structures_analysis.csv',
        'data/08_reporting/correlations_analysis.csv',
        'data/08_reporting/game_duration_analysis.csv',
        'data/08_reporting/eda_complete_report.json',
    ]
    
    print("="*60)
    print("VERIFICACIÃ“N DE ARCHIVOS GENERADOS")
    print("="*60)
    
    todos_existen = True
    
    for archivo in archivos_esperados:
        existe = os.path.exists(archivo)
        estado = "âœ…" if existe else "âŒ"
        print(f"{estado} {archivo}")
        
        if existe and archivo.endswith('.csv'):
            try:
                df = pd.read_csv(archivo)
                print(f"   ğŸ“Š {len(df)} filas, {len(df.columns)} columnas")
            except Exception as e:
                print(f"   âš ï¸  Error al leer: {str(e)}")
        
        todos_existen = todos_existen and existe
    
    print("="*60)
    if todos_existen:
        print("âœ… TODOS LOS ARCHIVOS FUERON GENERADOS CORRECTAMENTE")
    else:
        print("âŒ FALTAN ALGUNOS ARCHIVOS")
    print("="*60)
    
    return todos_existen

if __name__ == "__main__":
    verificar_archivos()
```

Ejecutar:
```bash
python verificar_pipelines.py
```

---

## ğŸ› SoluciÃ³n de Problemas

### Error: "Dataset not found"

```
DatasetError: Failed while loading data from data set raw_main_data
```

**SoluciÃ³n:**
- Verificar que el archivo existe: `data/01_raw/LeagueofLegends.csv`
- Verificar configuraciÃ³n en `conf/base/catalog.yml`

### Error: "No module named 'league_project.pipelines.data_cleaning'"

**SoluciÃ³n:**
```bash
# Reinstalar el proyecto
pip install -e .
```

### Error: "UnicodeDecodeError"

**SoluciÃ³n:**
- Los nodos de limpieza ya manejan mÃºltiples encodings automÃ¡ticamente
- Si persiste, verificar el encoding del archivo CSV

### Pipeline muy lento

**SoluciÃ³n:**
```bash
# Ejecutar pipelines en paralelo (si son independientes)
kedro run --pipeline data_cleaning --parallel

# Reducir tamaÃ±o de datos para prueba
# Editar el nodo para usar .head(1000) temporalmente
```

---

## ğŸ“ PrÃ³ximos Pasos

DespuÃ©s de ejecutar la limpieza y exploraciÃ³n:

1. **Revisar los reportes generados**
   - Ver `data/08_reporting/`
   - Identificar insights clave

2. **Ejecutar Feature Engineering**
   ```bash
   kedro run --pipeline data_processing
   ```

3. **Entrenar Modelos**
   ```bash
   kedro run --pipeline data_science
   ```

4. **Evaluar Resultados**
   ```bash
   kedro run --pipeline evaluation
   ```

---

## ğŸ¯ Resumen de Comandos

```bash
# Limpieza de datos
kedro run --pipeline data_cleaning

# ExploraciÃ³n de datos
kedro run --pipeline data_exploration

# Limpieza + ExploraciÃ³n
kedro run --pipeline eda

# Todo el proyecto
kedro run

# Ver logs
Get-Content info.log -Wait

# Listar pipelines disponibles
kedro pipeline list

# Ver informaciÃ³n del proyecto
kedro info
```

---

**ğŸ® Â¡Listos para analizar datos de League of Legends!** Los pipelines estÃ¡n configurados y listos para ejecutarse.

