# üéÆ League of Legends ML Project - Docker + Airflow Edition

<div align="center">

![Project Status](https://img.shields.io/badge/Status-Production%20Ready-success)
![Docker](https://img.shields.io/badge/Docker-Enabled-blue)
![Airflow](https://img.shields.io/badge/Airflow-2.8.0-red)
![Kedro](https://img.shields.io/badge/Kedro-1.0.0-orange)
![Python](https://img.shields.io/badge/Python-3.11-blue)

**An√°lisis de Machine Learning del League of Legends World Championship**  
**Con orquestaci√≥n autom√°tica y deployment en Windows**

[Quick Start](#-quick-start) ‚Ä¢
[Documentaci√≥n](#-documentaci√≥n) ‚Ä¢
[Arquitectura](#-arquitectura) ‚Ä¢
[Pipelines](#-pipelines) ‚Ä¢
[DAGs](#-dags-de-airflow)

</div>

---

## üåü Caracter√≠sticas

- ‚úÖ **5 Pipelines de Kedro** completamente funcionales
- ‚úÖ **10 Modelos de ML** (5 regresi√≥n + 5 clasificaci√≥n)
- ‚úÖ **3 DAGs de Airflow** para orquestaci√≥n automatizada
- ‚úÖ **Docker Compose** para deployment multi-container
- ‚úÖ **Scripts PowerShell** optimizados para Windows
- ‚úÖ **Documentaci√≥n completa** con gu√≠as paso a paso
- ‚úÖ **33+ Nodos** de procesamiento modular
- ‚úÖ **7 Datasets** procesados y analizados

---

## üöÄ Quick Start

### Prerrequisitos
- Docker Desktop instalado
- Windows 10/11
- 8+ GB RAM

### 3 Comandos para Empezar

```powershell
# 1. Setup autom√°tico
.\setup_airflow_windows.ps1

# 2. Iniciar servicios
docker-compose up -d

# 3. Ejecutar tu primer pipeline
.\run_kedro_pipeline.ps1 -Pipeline eda
```

### Acceder a Airflow
- **URL**: http://localhost:8080
- **Usuario**: `admin`
- **Contrase√±a**: `admin`

---

## üìö Documentaci√≥n

| Documento | Descripci√≥n |
|-----------|-------------|
| **[QUICK_START.md](QUICK_START.md)** | ‚ö° Inicio r√°pido en 5 minutos |
| **[DOCKER_AIRFLOW_GUIDE.md](DOCKER_AIRFLOW_GUIDE.md)** | üìñ Gu√≠a completa y detallada |
| **[DEPLOYMENT_SUMMARY.md](DEPLOYMENT_SUMMARY.md)** | üì¶ Resumen ejecutivo del deployment |
| **[airflow/dags/README.md](airflow/dags/README.md)** | üìä Documentaci√≥n de DAGs |
| **[GUIA_DATOS_CSV.md](docs/GUIA_DATOS_CSV.md)** | üìÅ Gu√≠a de datos CSV |

---

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   AIRFLOW ORCHESTRATOR                 ‚îÇ
‚îÇ                    (localhost:8080)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº            ‚ñº            ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  EDA   ‚îÇ   ‚îÇ   ML   ‚îÇ   ‚îÇ  Full  ‚îÇ
    ‚îÇ  DAG   ‚îÇ   ‚îÇ  DAG   ‚îÇ   ‚îÇ  DAG   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ           ‚îÇ            ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   KEDRO PIPELINES     ‚îÇ
         ‚îÇ                       ‚îÇ
         ‚îÇ  1. Data Cleaning     ‚îÇ
         ‚îÇ  2. Data Exploration  ‚îÇ
         ‚îÇ  3. Data Processing   ‚îÇ
         ‚îÇ  4. Model Training    ‚îÇ
         ‚îÇ  5. Model Evaluation  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ    DATA & MODELS      ‚îÇ
         ‚îÇ                       ‚îÇ
         ‚îÇ  ‚Ä¢ Cleaned Data       ‚îÇ
         ‚îÇ  ‚Ä¢ Features           ‚îÇ
         ‚îÇ  ‚Ä¢ Trained Models     ‚îÇ
         ‚îÇ  ‚Ä¢ Reports            ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Pipelines

### 1. Data Cleaning Pipeline
**Nodos**: 8 | **Tiempo**: ~1 min  
Limpia 7 datasets raw eliminando duplicados, manejando nulos y detectando outliers.

### 2. Data Exploration Pipeline
**Nodos**: 8 | **Tiempo**: ~30 seg  
Genera an√°lisis estad√≠sticos completos incluyendo:
- üìà Estad√≠sticas descriptivas
- üèÜ An√°lisis de rendimiento de 246 equipos
- üö´ An√°lisis de 137 campeones baneados
- üêâ Objetivos neutrales y estructuras
- üîó Matriz de correlaciones

### 3. Data Processing Pipeline
**Nodos**: 7 | **Tiempo**: ~2 min  
Feature engineering con agregaciones de:
- üíÄ Kills por equipo
- üêâ Dragones y Barones
- üè∞ Torres e Inhibidores
- üí∞ Diferencias de oro
- üìä Escalado de features

### 4. Data Science Pipeline
**Nodos**: 4 | **Tiempo**: ~5 min  
Entrena 10 modelos de ML:

**Regresi√≥n** (predecir duraci√≥n):
- Linear Regression, Ridge, Lasso
- Random Forest, Gradient Boosting

**Clasificaci√≥n** (predecir ganador):
- Logistic Regression, Random Forest, GradientBoosting
- SVM, Naive Bayes

### 5. Evaluation Pipeline
**Nodos**: 6 | **Tiempo**: ~1 min  
Eval√∫a modelos con m√∫ltiples m√©tricas:
- **Regresi√≥n**: RMSE, MAE, R¬≤
- **Clasificaci√≥n**: Accuracy, Precision, Recall, F1, AUC-ROC
- **Feature Importance** de modelos basados en √°rboles

---

## üìÖ DAGs de Airflow

### 1. `kedro_league_ml_pipeline`
**Schedule**: Semanal  
**Duraci√≥n**: ~15 min  
Pipeline completo de ML desde limpieza hasta evaluaci√≥n.

### 2. `kedro_eda_pipeline`
**Schedule**: Diario  
**Duraci√≥n**: ~3 min  
Solo limpieza y exploraci√≥n para monitoreo de calidad de datos.

### 3. `kedro_model_training_pipeline`
**Schedule**: Manual  
**Duraci√≥n**: ~8 min  
Solo entrenamiento y evaluaci√≥n (con verificaci√≥n de datos procesados).

---

## üéØ Comandos √ötiles

### Gesti√≥n de Servicios

```powershell
# Iniciar todo
docker-compose up -d

# Ver estado
docker-compose ps

# Ver logs
docker-compose logs -f

# Detener todo
docker-compose down

# Reiniciar un servicio
docker-compose restart airflow-scheduler
```

### Ejecutar Pipelines

```powershell
# Con script (recomendado)
.\run_kedro_pipeline.ps1 -Pipeline eda
.\run_kedro_pipeline.ps1 -Pipeline data_science

# Directo con docker-compose
docker-compose run --rm kedro-app kedro run
docker-compose run --rm kedro-app kedro run --pipeline eda

# Ver pipelines disponibles
docker-compose run --rm kedro-app kedro pipeline list
```

### Debugging

```powershell
# Logs de Airflow
docker-compose logs -f airflow-scheduler

# Shell en contenedor de Kedro
docker-compose run --rm kedro-app bash

# Ver cat√°logo de datos
docker-compose run --rm kedro-app kedro catalog list
```

---

## üìÅ Estructura del Proyecto

```
league-project/
‚îú‚îÄ‚îÄ üìÑ Dockerfile                    # Imagen de Kedro
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml            # Orquestaci√≥n multi-container
‚îú‚îÄ‚îÄ üìÑ setup_airflow_windows.ps1    # Script de setup
‚îú‚îÄ‚îÄ üìÑ run_kedro_pipeline.ps1       # Ejecutor de pipelines
‚îú‚îÄ‚îÄ üìÑ Makefile                      # Comandos √∫tiles
‚îÇ
‚îú‚îÄ‚îÄ üìÅ airflow/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ dags/                     # DAGs de Airflow
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kedro_league_ml_dag.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kedro_eda_only_dag.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kedro_training_only_dag.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ logs/                     # Logs de Airflow
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ plugins/                  # Plugins personalizados
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ config/                   # Configuraci√≥n
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ league_project/
‚îÇ       ‚îî‚îÄ‚îÄ üìÅ pipelines/
‚îÇ           ‚îú‚îÄ‚îÄ üìÅ data_cleaning/
‚îÇ           ‚îú‚îÄ‚îÄ üìÅ data_exploration/
‚îÇ           ‚îú‚îÄ‚îÄ üìÅ data_processing/
‚îÇ           ‚îú‚îÄ‚îÄ üìÅ data_science/
‚îÇ           ‚îî‚îÄ‚îÄ üìÅ evaluation/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ 01_raw/                   # Datos originales
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ 02_intermediate/          # Datos limpios
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ 05_model_input/           # Features procesadas
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ 06_models/                # Modelos entrenados
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ 08_reporting/             # Reportes y m√©tricas
‚îÇ
‚îî‚îÄ‚îÄ üìÅ docs/                         # Documentaci√≥n completa
```

---

## üîç Resultados Esperados

Despu√©s de ejecutar el pipeline completo, tendr√°s:

### Datos Procesados
- ‚úÖ 7 datasets limpios en `data/02_intermediate/`
- ‚úÖ Features engineered en `data/05_model_input/`

### An√°lisis Exploratorio
- ‚úÖ Estad√≠sticas de 246 equipos
- ‚úÖ An√°lisis de 137 campeones
- ‚úÖ Reporte completo de EDA en JSON

### Modelos Entrenados
- ‚úÖ 5 modelos de regresi√≥n (duraci√≥n de partida)
- ‚úÖ 5 modelos de clasificaci√≥n (predicci√≥n de ganador)
- ‚úÖ M√©tricas comparativas en CSV

### Evaluaci√≥n
- ‚úÖ Feature importance por modelo
- ‚úÖ Reportes JSON con mejores modelos
- ‚úÖ M√©tricas de rendimiento (R¬≤, F1, AUC)

---

## üõ†Ô∏è Soluci√≥n de Problemas

### Puerto 8080 ocupado
```powershell
# Editar docker-compose.yml l√≠nea 73
# Cambiar "8080:8080" a "8081:8080"
```

### DAGs no aparecen en Airflow
```powershell
docker-compose restart airflow-scheduler
```

### Error de memoria
```powershell
# En Docker Desktop > Settings > Resources
# Aumentar RAM a 8+ GB
```

### Logs completos
```powershell
# Ver logs de todos los servicios
docker-compose logs --tail=100

# Logs de un contenedor espec√≠fico
docker-compose logs -f kedro-app
```

---

## üìà M√©tricas del Proyecto

| Categor√≠a | Cantidad |
|-----------|----------|
| **Pipelines** | 5 |
| **Nodos** | 33+ |
| **Modelos ML** | 10 |
| **DAGs Airflow** | 3 |
| **Datasets** | 7 |
| **Documentos** | 6 |
| **Scripts PowerShell** | 2 |

---

## ü§ù Contribuir

¬øMejoras o sugerencias?

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## üìù Licencia

Este proyecto es de c√≥digo abierto y est√° disponible bajo la licencia MIT.

---

## üë• Autores

**League ML Team**
- Machine Learning Engineering
- Data Pipeline Development
- Docker & Airflow Integration

---

## üôè Agradecimientos

- **Kedro Team** por el excelente framework
- **Apache Airflow** por la orquestaci√≥n robusta
- **Docker** por la containerizaci√≥n
- **Riot Games** por los datos de League of Legends

---

## üìû Soporte

¬øNecesitas ayuda? Consulta:

1. **[QUICK_START.md](QUICK_START.md)** - Inicio r√°pido
2. **[DOCKER_AIRFLOW_GUIDE.md](DOCKER_AIRFLOW_GUIDE.md)** - Gu√≠a detallada
3. **[Issues](https://github.com/tu-repo/issues)** - Reportar problemas

---

<div align="center">

### üéâ ¬°Sistema Listo para Producci√≥n!

**Con Docker, Airflow y Kedro trabajando juntos**

[‚¨Ü Volver arriba](#-league-of-legends-ml-project---docker--airflow-edition)

</div>


