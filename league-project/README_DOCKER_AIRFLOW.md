# ğŸ® League of Legends ML Project - Docker + Airflow Edition

<div align="center">

![Project Status](https://img.shields.io/badge/Status-Production%20Ready-success)
![Docker](https://img.shields.io/badge/Docker-Enabled-blue)
![Airflow](https://img.shields.io/badge/Airflow-2.8.0-red)
![Kedro](https://img.shields.io/badge/Kedro-1.0.0-orange)
![Python](https://img.shields.io/badge/Python-3.11-blue)

**AnÃ¡lisis de Machine Learning del League of Legends World Championship**  
**Con orquestaciÃ³n automÃ¡tica y deployment en Windows**

[Quick Start](#-quick-start) â€¢
[DocumentaciÃ³n](#-documentaciÃ³n) â€¢
[Arquitectura](#-arquitectura) â€¢
[Pipelines](#-pipelines) â€¢
[DAGs](#-dags-de-airflow)

</div>

---

## ğŸŒŸ CaracterÃ­sticas

- âœ… **5 Pipelines de Kedro** completamente funcionales
- âœ… **10 Modelos de ML** (5 regresiÃ³n + 5 clasificaciÃ³n)
- âœ… **3 DAGs de Airflow** para orquestaciÃ³n automatizada
- âœ… **Docker Compose** para deployment multi-container
- âœ… **Scripts PowerShell** optimizados para Windows
- âœ… **DocumentaciÃ³n completa** con guÃ­as paso a paso
- âœ… **33+ Nodos** de procesamiento modular
- âœ… **7 Datasets** procesados y analizados

---

## ğŸš€ Quick Start

### Prerrequisitos
- Docker Desktop instalado
- Windows 10/11
- 8+ GB RAM

### 3 Comandos para Empezar

```powershell
# 1. Setup automÃ¡tico
.\setup_airflow_windows.ps1

# 2. Iniciar servicios
docker-compose up -d

# 3. Ejecutar tu primer pipeline
.\run_kedro_pipeline.ps1 -Pipeline eda
```

### Acceder a Airflow
- **URL**: http://localhost:8080
- **Usuario**: `admin`
- **ContraseÃ±a**: `admin`

---

## ğŸ“š DocumentaciÃ³n

| Documento | DescripciÃ³n |
|-----------|-------------|
| **[QUICK_START.md](QUICK_START.md)** | âš¡ Inicio rÃ¡pido en 5 minutos |
| **[DOCKER_AIRFLOW_GUIDE.md](DOCKER_AIRFLOW_GUIDE.md)** | ğŸ“– GuÃ­a completa y detallada |
| **[DEPLOYMENT_SUMMARY.md](DEPLOYMENT_SUMMARY.md)** | ğŸ“¦ Resumen ejecutivo del deployment |
| **[airflow/dags/README.md](airflow/dags/README.md)** | ğŸ“Š DocumentaciÃ³n de DAGs |
| **[GUIA_DATOS_CSV.md](docs/GUIA_DATOS_CSV.md)** | ğŸ“ GuÃ­a de datos CSV |

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AIRFLOW ORCHESTRATOR                 â”‚
â”‚                    (localhost:8080)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼            â–¼            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  EDA   â”‚   â”‚   ML   â”‚   â”‚  Full  â”‚
    â”‚  DAG   â”‚   â”‚  DAG   â”‚   â”‚  DAG   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚           â”‚            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   KEDRO PIPELINES     â”‚
         â”‚                       â”‚
         â”‚  1. Data Cleaning     â”‚
         â”‚  2. Data Exploration  â”‚
         â”‚  3. Data Processing   â”‚
         â”‚  4. Model Training    â”‚
         â”‚  5. Model Evaluation  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    DATA & MODELS      â”‚
         â”‚                       â”‚
         â”‚  â€¢ Cleaned Data       â”‚
         â”‚  â€¢ Features           â”‚
         â”‚  â€¢ Trained Models     â”‚
         â”‚  â€¢ Reports            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Pipelines

### 1. Data Cleaning Pipeline
**Nodos**: 8 | **Tiempo**: ~1 min  
Limpia 7 datasets raw eliminando duplicados, manejando nulos y detectando outliers.

### 2. Data Exploration Pipeline
**Nodos**: 8 | **Tiempo**: ~30 seg  
Genera anÃ¡lisis estadÃ­sticos completos incluyendo:
- ğŸ“ˆ EstadÃ­sticas descriptivas
- ğŸ† AnÃ¡lisis de rendimiento de 246 equipos
- ğŸš« AnÃ¡lisis de 137 campeones baneados
- ğŸ‰ Objetivos neutrales y estructuras
- ğŸ”— Matriz de correlaciones

### 3. Data Processing Pipeline
**Nodos**: 7 | **Tiempo**: ~2 min  
Feature engineering con agregaciones de:
- ğŸ’€ Kills por equipo
- ğŸ‰ Dragones y Barones
- ğŸ° Torres e Inhibidores
- ğŸ’° Diferencias de oro
- ğŸ“Š Escalado de features

### 4. Data Science Pipeline
**Nodos**: 4 | **Tiempo**: ~5 min  
Entrena 10 modelos de ML:

**RegresiÃ³n** (predecir duraciÃ³n):
- Linear Regression, Ridge, Lasso
- Random Forest, Gradient Boosting

**ClasificaciÃ³n** (predecir ganador):
- Logistic Regression, Random Forest, GradientBoosting
- SVM, Naive Bayes

### 5. Evaluation Pipeline
**Nodos**: 6 | **Tiempo**: ~1 min  
EvalÃºa modelos con mÃºltiples mÃ©tricas:
- **RegresiÃ³n**: RMSE, MAE, RÂ²
- **ClasificaciÃ³n**: Accuracy, Precision, Recall, F1, AUC-ROC
- **Feature Importance** de modelos basados en Ã¡rboles

---

## ğŸ“… DAGs de Airflow

### 1. `kedro_league_ml_pipeline`
**Schedule**: Semanal  
**DuraciÃ³n**: ~15 min  
Pipeline completo de ML desde limpieza hasta evaluaciÃ³n.

### 2. `kedro_eda_pipeline`
**Schedule**: Diario  
**DuraciÃ³n**: ~3 min  
Solo limpieza y exploraciÃ³n para monitoreo de calidad de datos.

### 3. `kedro_model_training_pipeline`
**Schedule**: Manual  
**DuraciÃ³n**: ~8 min  
Solo entrenamiento y evaluaciÃ³n (con verificaciÃ³n de datos procesados).

---

## ğŸ¯ Comandos Ãštiles

### GestiÃ³n de Servicios

```powershell
# Iniciar todo
docker-compose up -d

# Ver estado
docker-compose ps

# Ver logs
docker-compose logs -f

# Detener todo
docker-compose down

# Reiniciar un servicio
docker-compose restart airflow-scheduler
```

### Ejecutar Pipelines

```powershell
# Con script (recomendado)
.\run_kedro_pipeline.ps1 -Pipeline eda
.\run_kedro_pipeline.ps1 -Pipeline data_science

# Directo con docker-compose
docker-compose run --rm kedro-app kedro run
docker-compose run --rm kedro-app kedro run --pipeline eda

# Ver pipelines disponibles
docker-compose run --rm kedro-app kedro pipeline list
```

### Debugging

```powershell
# Logs de Airflow
docker-compose logs -f airflow-scheduler

# Shell en contenedor de Kedro
docker-compose run --rm kedro-app bash

# Ver catÃ¡logo de datos
docker-compose run --rm kedro-app kedro catalog list
```

---

## ğŸ“ Estructura del Proyecto

```
league-project/
â”œâ”€â”€ ğŸ“„ Dockerfile                    # Imagen de Kedro
â”œâ”€â”€ ğŸ“„ docker-compose.yml            # OrquestaciÃ³n multi-container
â”œâ”€â”€ ğŸ“„ setup_airflow_windows.ps1    # Script de setup
â”œâ”€â”€ ğŸ“„ run_kedro_pipeline.ps1       # Ejecutor de pipelines
â”œâ”€â”€ ğŸ“„ Makefile                      # Comandos Ãºtiles
â”‚
â”œâ”€â”€ ğŸ“ airflow/
â”‚   â”œâ”€â”€ ğŸ“ dags/                     # DAGs de Airflow
â”‚   â”‚   â”œâ”€â”€ kedro_league_ml_dag.py
â”‚   â”‚   â”œâ”€â”€ kedro_eda_only_dag.py
â”‚   â”‚   â”œâ”€â”€ kedro_training_only_dag.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ ğŸ“ logs/                     # Logs de Airflow
â”‚   â”œâ”€â”€ ğŸ“ plugins/                  # Plugins personalizados
â”‚   â””â”€â”€ ğŸ“ config/                   # ConfiguraciÃ³n
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â””â”€â”€ ğŸ“ league_project/
â”‚       â””â”€â”€ ğŸ“ pipelines/
â”‚           â”œâ”€â”€ ğŸ“ data_cleaning/
â”‚           â”œâ”€â”€ ğŸ“ data_exploration/
â”‚           â”œâ”€â”€ ğŸ“ data_processing/
â”‚           â”œâ”€â”€ ğŸ“ data_science/
â”‚           â””â”€â”€ ğŸ“ evaluation/
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ ğŸ“ 01_raw/                   # Datos originales
â”‚   â”œâ”€â”€ ğŸ“ 02_intermediate/          # Datos limpios
â”‚   â”œâ”€â”€ ğŸ“ 05_model_input/           # Features procesadas
â”‚   â”œâ”€â”€ ğŸ“ 06_models/                # Modelos entrenados
â”‚   â””â”€â”€ ğŸ“ 08_reporting/             # Reportes y mÃ©tricas
â”‚
â””â”€â”€ ğŸ“ docs/                         # DocumentaciÃ³n completa
```

---

## ğŸ” Resultados Esperados

DespuÃ©s de ejecutar el pipeline completo, tendrÃ¡s:

### Datos Procesados
- âœ… 7 datasets limpios en `data/02_intermediate/`
- âœ… Features engineered en `data/05_model_input/`

### AnÃ¡lisis Exploratorio
- âœ… EstadÃ­sticas de 246 equipos
- âœ… AnÃ¡lisis de 137 campeones
- âœ… Reporte completo de EDA en JSON

### Modelos Entrenados
- âœ… 5 modelos de regresiÃ³n (duraciÃ³n de partida)
- âœ… 5 modelos de clasificaciÃ³n (predicciÃ³n de ganador)
- âœ… MÃ©tricas comparativas en CSV

### EvaluaciÃ³n
- âœ… Feature importance por modelo
- âœ… Reportes JSON con mejores modelos
- âœ… MÃ©tricas de rendimiento (RÂ², F1, AUC)

---

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Puerto 8080 ocupado
```powershell
# Editar docker-compose.yml lÃ­nea 73
# Cambiar "8080:8080" a "8081:8080"
```

### DAGs no aparecen en Airflow
```powershell
docker-compose restart airflow-scheduler
```

### Error de memoria
```powershell
# En Docker Desktop > Settings > Resources
# Aumentar RAM a 8+ GB
```

### Logs completos
```powershell
# Ver logs de todos los servicios
docker-compose logs --tail=100

# Logs de un contenedor especÃ­fico
docker-compose logs -f kedro-app
```

---

## ğŸ“ˆ MÃ©tricas del Proyecto

| CategorÃ­a | Cantidad |
|-----------|----------|
| **Pipelines** | 5 |
| **Nodos** | 33+ |
| **Modelos ML** | 10 |
| **DAGs Airflow** | 3 |
| **Datasets** | 7 |
| **Documentos** | 6 |
| **Scripts PowerShell** | 2 |

---

## ğŸ¤ Contribuir

Â¿Mejoras o sugerencias?

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.

---

## ğŸ‘¥ Autores

**League ML Team**
- Machine Learning Engineering
- Data Pipeline Development
- Docker & Airflow Integration

---

## ğŸ™ Agradecimientos

- **Kedro Team** por el excelente framework
- **Apache Airflow** por la orquestaciÃ³n robusta
- **Docker** por la containerizaciÃ³n
- **Riot Games** por los datos de League of Legends

---

## ğŸ“ Soporte

Â¿Necesitas ayuda? Consulta:

1. **[QUICK_START.md](QUICK_START.md)** - Inicio rÃ¡pido
2. **[DOCKER_AIRFLOW_GUIDE.md](DOCKER_AIRFLOW_GUIDE.md)** - GuÃ­a detallada
3. **[Issues](https://github.com/tu-repo/issues)** - Reportar problemas

---

<div align="center">

### ğŸ‰ Â¡Sistema Listo para ProducciÃ³n!

**Con Docker, Airflow y Kedro trabajando juntos**

[â¬† Volver arriba](#-league-of-legends-ml-project---docker--airflow-edition)

</div>


