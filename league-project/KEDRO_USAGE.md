# GuÃ­a de Uso - Proyecto Kedro de League of Legends

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline completo de Machine Learning siguiendo la metodologÃ­a **CRISP-DM** para analizar partidas profesionales de League of Legends.

### Objetivos

1. **RegresiÃ³n**: Predecir la duraciÃ³n de una partida (`gamelength`)
2. **ClasificaciÃ³n**: Predecir el resultado de una partida (`bResult` - victoria/derrota del equipo azul)

## ğŸ“ Estructura de Pipelines

El proyecto estÃ¡ organizado en 3 pipelines modulares:

### 1. **data_processing** 
Feature engineering y preparaciÃ³n de datos
- AgregaciÃ³n de kills, dragones, barones, torres
- ExtracciÃ³n de diferencias de oro
- SelecciÃ³n de features
- DivisiÃ³n train/test
- EstandarizaciÃ³n con StandardScaler

### 2. **data_science**
Entrenamiento de modelos
- **RegresiÃ³n**: Linear, Ridge, Lasso, Random Forest, Gradient Boosting
- **ClasificaciÃ³n**: Logistic Regression, Random Forest, Gradient Boosting, SVM, Naive Bayes

### 3. **evaluation**
EvaluaciÃ³n y reportes
- MÃ©tricas de regresiÃ³n: RMSE, MAE, RÂ²
- MÃ©tricas de clasificaciÃ³n: Accuracy, Precision, Recall, F1, AUC-ROC
- Feature importance
- Reportes en JSON

## ğŸš€ EjecuciÃ³n del Pipeline

### Ejecutar Pipeline Completo

```bash
kedro run
```

Esto ejecutarÃ¡ los 3 pipelines en secuencia: data_processing â†’ data_science â†’ evaluation

### Ejecutar Pipelines Individuales

```bash
# Solo procesamiento de datos
kedro run --pipeline=data_processing
kedro run --pipeline=dp  # Alias corto

# Solo entrenamiento de modelos
kedro run --pipeline=data_science
kedro run --pipeline=ds  # Alias corto

# Solo evaluaciÃ³n
kedro run --pipeline=evaluation
kedro run --pipeline=eval  # Alias corto
```

### Ejecutar desde un nodo especÃ­fico

```bash
# Desde el nodo de escalado en adelante
kedro run --from-nodes=scale_features_node

# Hasta un nodo especÃ­fico
kedro run --to-nodes=select_features_node

# Ejecutar solo un nodo
kedro run --node=train_regression_models_node
```

## ğŸ“Š VisualizaciÃ³n del Pipeline

### Ver estructura del pipeline

```bash
kedro viz
```

Esto abrirÃ¡ una interfaz web interactiva donde podrÃ¡s:
- Ver el grafo completo de dependencias
- Inspeccionar cada nodo
- Ver los datasets intermedios
- Analizar el flujo de datos

## ğŸ“‚ Outputs del Pipeline

DespuÃ©s de ejecutar el pipeline, encontrarÃ¡s:

### Datos Procesados
- `data/02_intermediate/`: Features intermedios
- `data/03_primary/`: Datos listos para modelado
- `data/04_feature/`: Train/test split y datos escalados

### Modelos Entrenados
- `data/06_models/regression_models.pkl`
- `data/06_models/classification_models.pkl`
- `data/06_models/scaler.pkl`

### Reportes y MÃ©tricas
- `data/08_reporting/regression_metrics.parquet`
- `data/08_reporting/classification_metrics.parquet`
- `data/08_reporting/regression_report.json`
- `data/08_reporting/classification_report.json`
- `data/08_reporting/regression_feature_importance.parquet`
- `data/08_reporting/classification_feature_importance.parquet`

## ğŸ”§ ConfiguraciÃ³n

### Modificar ParÃ¡metros

Edita `conf/base/parameters.yml` para cambiar:

- HiperparÃ¡metros de modelos
- Features utilizados
- TamaÃ±o del test set
- Random seed

Ejemplo:
```yaml
model_options:
  test_size: 0.3  # Cambiar a 70/30 split
  
  regression_models:
    rf_n_estimators: 200  # MÃ¡s Ã¡rboles en Random Forest
    rf_max_depth: 20      # Mayor profundidad
```

### Modificar Datasets

Edita `conf/base/catalog.yml` para:
- Cambiar ubicaciones de archivos
- Modificar formatos (CSV, Parquet, Pickle)
- Agregar nuevos datasets

## ğŸ“ˆ Ver Resultados

### Leer Reportes en Python

```python
import json
import pandas as pd

# Leer reporte de regresiÃ³n
with open('data/08_reporting/regression_report.json', 'r') as f:
    reg_report = json.load(f)

print(f"Mejor modelo: {reg_report['best_model']}")
print(f"RÂ² Score: {reg_report['best_r2']:.4f}")

# Leer mÃ©tricas
metrics = pd.read_parquet('data/08_reporting/regression_metrics.parquet')
print(metrics)
```

### Ver Logs

Los logs se guardan en `logs/` y tambiÃ©n se muestran en consola durante la ejecuciÃ³n.

## ğŸ§ª Testing

```bash
# Ejecutar tests
pytest

# Con cobertura
pytest --cov=league_project
```

## ğŸ“ Comandos Ãštiles de Kedro

```bash
# Listar todos los pipelines
kedro registry list

# Listar todos los nodos de un pipeline
kedro registry describe data_processing

# Ver catÃ¡logo de datos
kedro catalog list

# Ver detalles de un dataset
kedro catalog describe regression_models

# Crear documentaciÃ³n
kedro build-docs

# Empaquetar proyecto
kedro package
```

## ğŸ”„ Workflow TÃ­pico

1. **Desarrollo Inicial**
   ```bash
   kedro run  # Ejecutar pipeline completo
   kedro viz  # Visualizar resultados
   ```

2. **Ajuste de HiperparÃ¡metros**
   - Editar `conf/base/parameters.yml`
   - Ejecutar solo entrenamiento:
     ```bash
     kedro run --pipeline=data_science
     ```

3. **AÃ±adir Nuevas Features**
   - Modificar `src/league_project/pipelines/data_processing/nodes.py`
   - Actualizar lista de features en `parameters.yml`
   - Ejecutar desde data_processing:
     ```bash
     kedro run --from-nodes=aggregate_kills_node
     ```

4. **ExperimentaciÃ³n**
   - Los datos intermedios se cachean automÃ¡ticamente
   - Solo se re-ejecutan los nodos necesarios
   - Usa `--from-nodes` y `--to-nodes` para controlar la ejecuciÃ³n

## ğŸ“š Estructura de CÃ³digo

```
src/league_project/pipelines/
â”œâ”€â”€ data_processing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ nodes.py       # Funciones de procesamiento
â”‚   â””â”€â”€ pipeline.py    # DefiniciÃ³n del pipeline
â”œâ”€â”€ data_science/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ nodes.py       # Entrenamiento de modelos
â”‚   â””â”€â”€ pipeline.py    # DefiniciÃ³n del pipeline
â””â”€â”€ evaluation/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ nodes.py       # EvaluaciÃ³n y mÃ©tricas
    â””â”€â”€ pipeline.py    # DefiniciÃ³n del pipeline
```

## ğŸ“ Cumplimiento de CRISP-DM

âœ… **1. ComprensiÃ³n del Negocio**: Documentado en el README y comentarios del cÃ³digo

âœ… **2. ComprensiÃ³n de los Datos**: Pipeline `data_processing` - anÃ¡lisis inicial

âœ… **3. PreparaciÃ³n de los Datos**: Pipeline `data_processing` - feature engineering

âœ… **4. Modelado**: Pipeline `data_science` - mÃºltiples algoritmos

âœ… **5. EvaluaciÃ³n**: Pipeline `evaluation` - mÃ©tricas y comparaciones

âœ… **6. Despliegue**: CÃ³digo modular listo para producciÃ³n con Kedro

## ğŸ› ï¸ Troubleshooting

### Error: "Dataset not found"
```bash
# Verificar que los CSV existen en data/01_raw/
ls data/01_raw/

# Verificar catÃ¡logo
kedro catalog list
```

### Error: "Module not found"
```bash
# Reinstalar dependencias
pip install -r requirements.txt

# O instalar el proyecto en modo editable
pip install -e .
```

### Pipeline muy lento
```bash
# Ejecutar solo con un subset de datos
# Modificar temporalmente los nodos para usar .head(1000)
```

## ğŸ“ Ayuda Adicional

- DocumentaciÃ³n oficial de Kedro: https://docs.kedro.org
- Ver los notebooks en `notebooks/` para anÃ¡lisis exploratorio
- Revisar logs en `logs/` para debugging

---

## ğŸ¯ Next Steps

1. **OptimizaciÃ³n de HiperparÃ¡metros**: Agregar GridSearchCV
2. **ValidaciÃ³n Cruzada**: Implementar k-fold CV
3. **Modelos Avanzados**: XGBoost, LightGBM
4. **API REST**: Desplegar modelos con FastAPI
5. **Monitoreo**: Agregar MLflow para tracking

Â¡Disfruta explorando los datos de League of Legends! ğŸ®âš”ï¸



