# üöÄ Gu√≠a Completa de Ejecuci√≥n - League of Legends ML Project

**Autor:** Pedro Torres (glYohanny)  
**Email:** ped.torres@duocuc.cl  
**Repositorio:** https://github.com/glYohanny/Evaluacion_machine_learning

---

## üìã Tabla de Contenidos

1. [Requisitos Previos](#requisitos-previos)
2. [Instalaci√≥n](#instalaci√≥n)
3. [Opci√≥n 1: Ejecuci√≥n con Kedro (Recomendado)](#opci√≥n-1-ejecuci√≥n-con-kedro-recomendado)
4. [Opci√≥n 2: Ejecuci√≥n con Docker + Airflow](#opci√≥n-2-ejecuci√≥n-con-docker--airflow)
5. [Ver Resultados](#ver-resultados)
6. [Troubleshooting](#troubleshooting)

---

## üîß Requisitos Previos

### **Software Necesario:**

1. **Python 3.11** (o superior)
   - Descargar: https://www.python.org/downloads/
   - Verificar: `python --version`

2. **Git** (para clonar el repositorio)
   - Descargar: https://git-scm.com/downloads
   - Verificar: `git --version`

3. **Docker Desktop** (OPCIONAL - solo para Airflow)
   - Descargar: https://www.docker.com/products/docker-desktop
   - Verificar: `docker --version`

### **Hardware Recomendado:**
- RAM: 8GB m√≠nimo (16GB recomendado)
- Disco: 2GB libres
- CPU: 4 cores o m√°s

---

## üì• Instalaci√≥n

### **Paso 1: Clonar el Repositorio**

```bash
# Clonar el proyecto
git clone https://github.com/glYohanny/Evaluacion_machine_learning.git

# Navegar a la carpeta del proyecto
cd Evaluacion_machine_learning/league-project
```

### **Paso 2: Crear Virtual Environment**

**En Windows (PowerShell):**
```powershell
# Crear virtual environment
python -m venv venv

# Activar
.\venv\Scripts\Activate.ps1
```

**En Windows (CMD):**
```cmd
# Crear virtual environment
python -m venv venv

# Activar
venv\Scripts\activate.bat
```

**En Linux/Mac:**
```bash
# Crear virtual environment
python -m venv venv

# Activar
source venv/bin/activate
```

### **Paso 3: Instalar Dependencias**

```bash
# Actualizar pip
pip install --upgrade pip

# Instalar todas las dependencias
pip install -r requirements.txt
```

**Duraci√≥n:** 2-3 minutos

### **Paso 4: Verificar Instalaci√≥n**

```bash
# Verificar que Kedro est√° instalado
kedro --version

# Deber√≠a mostrar: kedro, version 1.0.0 (o similar)
```

---

## üéØ Opci√≥n 1: Ejecuci√≥n con Kedro (Recomendado)

Esta es la forma **M√ÅS R√ÅPIDA y SIMPLE** de ejecutar el proyecto.

### **A. Pipeline Completo (Recomendado)**

Ejecuta TODO el sistema de ML de principio a fin:

```bash
kedro run
```

**¬øQu√© hace?**
1. ‚úÖ Limpia 7 datasets raw
2. ‚úÖ Realiza an√°lisis exploratorio completo
3. ‚úÖ Crea 18 features ingenieradas
4. ‚úÖ Entrena 10 modelos de ML
5. ‚úÖ Eval√∫a con m√©tricas completas

**Duraci√≥n:** ~1-2 minutos  
**Output esperado:**
```
[INFO] Pipeline execution completed successfully in XX.X sec.
[INFO] Completed 33 out of 33 tasks
```

---

### **B. Pipelines Individuales**

Ejecuta partes espec√≠ficas del sistema:

#### **1. Solo Limpieza de Datos**
```bash
kedro run --pipeline data_cleaning
```
**Duraci√≥n:** ~15 segundos  
**Output:** Datasets limpios en `data/02_intermediate/`

#### **2. Solo An√°lisis Exploratorio (EDA)**
```bash
kedro run --pipeline data_exploration
```
**Duraci√≥n:** ~30 segundos  
**Output:** Reportes CSV en `data/08_reporting/`

#### **3. Limpieza + EDA (Recomendado para Demo R√°pida)**
```bash
kedro run --pipeline eda
```
**Duraci√≥n:** ~45 segundos  
**Output:** Datos limpios + 8 reportes de an√°lisis

#### **4. Feature Engineering**
```bash
kedro run --pipeline data_processing
```
**Duraci√≥n:** ~20 segundos  
**Output:** Features en `data/05_model_input/`

#### **5. Entrenamiento de Modelos**
```bash
kedro run --pipeline data_science
```
**Duraci√≥n:** ~30 segundos  
**Output:** 10 modelos en `data/06_models/`

#### **6. Evaluaci√≥n de Modelos**
```bash
kedro run --pipeline evaluation
```
**Duraci√≥n:** ~10 segundos  
**Output:** M√©tricas en `data/08_reporting/`

---

### **C. Ver Cat√°logo de Datos**

```bash
# Listar todos los datasets disponibles
kedro catalog list

# Ver estructura de un pipeline espec√≠fico
kedro catalog ds --pipeline data_cleaning
```

---

### **D. Ver Pipelines Disponibles**

```bash
# Listar todos los pipelines
kedro registry list
```

**Output esperado:**
```
- data_cleaning
- data_exploration
- data_processing
- data_science
- evaluation
- eda (combinado)
- __default__ (completo)
```

---

## üê≥ Opci√≥n 2: Ejecuci√≥n con Docker + Airflow

Esta opci√≥n es m√°s avanzada y muestra el sistema en **producci√≥n**.

### **Requisitos:**
- Docker Desktop instalado y corriendo
- 8GB RAM disponible

---

### **A. Setup Inicial (Solo Primera Vez)**

```powershell
# 1. Navegar a la carpeta del proyecto
cd league-project

# 2. Ejecutar script de setup
.\setup_airflow_windows.ps1
```

**¬øQu√© hace este script?**
1. ‚úÖ Verifica Docker Desktop
2. ‚úÖ Crea archivo `.env`
3. ‚úÖ Crea directorios de Airflow
4. ‚úÖ Construye imagen Docker con Kedro
5. ‚úÖ Inicializa base de datos de Airflow

**Duraci√≥n:** 10-15 minutos (primera vez)

---

### **B. Iniciar Servicios**

```powershell
# Levantar todos los servicios
docker-compose up -d
```

**¬øQu√© se inicia?**
- PostgreSQL (base de datos)
- Redis (message broker)
- Airflow Webserver (UI)
- Airflow Scheduler (orquestador)
- Aplicaci√≥n Kedro

**Duraci√≥n:** 30-60 segundos

---

### **C. Acceder a Airflow UI**

1. Abre navegador: http://localhost:8080
2. Login:
   - **Usuario:** `admin`
   - **Password:** `admin`

---

### **D. Ejecutar Pipelines en Airflow**

#### **DAG 1: kedro_eda_pipeline (An√°lisis Exploratorio)**

**Schedule:** Diario (@daily)

**Pasos:**
1. En la UI de Airflow, busca `kedro_eda_pipeline`
2. Click en el bot√≥n **‚ñ∂Ô∏è azul** (Trigger DAG)
3. Confirma "Trigger"
4. Click en el nombre del DAG para ver progreso
5. Ve a **"Graph View"** para ver el flujo

**Duraci√≥n:** ~3 minutos

**Tareas que ejecuta:**
- Clean 7 datasets
- Analyze teams (246 equipos)
- Analyze champions (137 campeones)
- Analyze correlations
- Generate reports

---

#### **DAG 2: kedro_league_ml_pipeline (Pipeline Completo)**

**Schedule:** Semanal (@weekly)

**Pasos:**
1. Click en `kedro_league_ml_pipeline`
2. Click en **‚ñ∂Ô∏è Trigger DAG**
3. Ve a **"Graph View"**

**Duraci√≥n:** ~15 minutos

**Tareas que ejecuta:**
1. data_cleaning
2. data_exploration
3. data_processing
4. model_training (10 modelos)
5. model_evaluation
6. generate_final_report

---

#### **DAG 3: kedro_model_training_pipeline (Solo Modelos)**

**Schedule:** Manual (None)

**Para qu√© sirve:** Reentrenar modelos sin reprocesar datos

**Pasos:**
1. Click en `kedro_model_training_pipeline`
2. Click en **‚ñ∂Ô∏è Trigger DAG**

**Duraci√≥n:** ~8 minutos

---

### **E. Ver Logs en Airflow**

1. Click en cualquier tarea (caja verde/amarilla/roja)
2. Click en **"Log"**
3. Ver√°s el output completo de Kedro

---

### **F. Detener Servicios**

```powershell
# Detener todos los servicios
docker-compose down

# Detener y eliminar vol√∫menes (limpieza completa)
docker-compose down -v
```

---

## üìä Ver Resultados

### **1. Reportes de An√°lisis Exploratorio**

```bash
# Listar todos los reportes
dir data/08_reporting/

# Ver estad√≠sticas descriptivas
type data/08_reporting/descriptive_statistics.csv

# Ver an√°lisis de equipos
type data/08_reporting/team_performance_analysis.csv

# Ver an√°lisis de campeones
type data/08_reporting/champion_bans_analysis.csv
```

**Reportes generados:**
- `descriptive_statistics.csv` - Estad√≠sticas b√°sicas
- `team_performance_analysis.csv` - 246 equipos analizados
- `champion_bans_analysis.csv` - 137 campeones
- `neutral_objectives_analysis.csv` - Dragones, Barones
- `structures_analysis.csv` - Torres, Inhibidores
- `correlations_analysis.csv` - Matriz de correlaci√≥n
- `game_duration_analysis.csv` - An√°lisis temporal
- `data_quality_report.csv` - Calidad de datos
- `eda_complete_report.json` - Reporte consolidado

---

### **2. M√©tricas de Modelos**

```bash
# Ver m√©tricas de clasificaci√≥n
type data/08_reporting/classification_metrics.parquet

# Ver m√©tricas de regresi√≥n
type data/08_reporting/regression_metrics.parquet

# Ver reporte completo de clasificaci√≥n
type data/08_reporting/classification_report.json

# Ver reporte completo de regresi√≥n
type data/08_reporting/regression_report.json
```

---

### **3. Modelos Entrenados**

```bash
# Listar modelos guardados
dir data/06_models/

# Deber√≠as ver 10 archivos .pkl:
# - linear_regression.pkl
# - ridge_regression.pkl
# - lasso_regression.pkl
# - random_forest_regressor.pkl
# - gradient_boosting_regressor.pkl
# - logistic_regression.pkl
# - random_forest_classifier.pkl
# - gradient_boosting_classifier.pkl
# - svm.pkl
# - naive_bayes.pkl
```

---

### **4. Resultados Esperados**

#### **Clasificaci√≥n (Predicci√≥n de Ganador):**

| Modelo | Accuracy | F1-Score | AUC-ROC |
|--------|----------|----------|---------|
| **SVM** ü•á | **98.56%** | **0.9868** | **0.9988** |
| Logistic Regression | 98.36% | 0.9851 | 0.9991 |
| Random Forest | 98.23% | 0.9838 | 0.9988 |
| Gradient Boosting | 98.16% | 0.9832 | 0.9990 |
| Naive Bayes | 97.05% | 0.9729 | 0.9895 |

**üèÜ Mejor Modelo:** SVM con 98.56% accuracy

---

#### **Regresi√≥n (Predicci√≥n de Duraci√≥n):**

| Modelo | RMSE | MAE | R¬≤ |
|--------|------|-----|-----|
| **Gradient Boosting** ü•á | **3.70** | **2.85** | **0.7928** |
| Ridge | 3.95 | 3.08 | 0.7634 |
| Linear Regression | 3.95 | 3.08 | 0.7633 |
| Random Forest | 3.96 | 3.02 | 0.7624 |
| Lasso | 3.97 | 3.10 | 0.7610 |

**üèÜ Mejor Modelo:** Gradient Boosting con R¬≤ 0.7928

---

## üîç Troubleshooting

### **Problema 1: "ModuleNotFoundError: No module named 'kedro'"**

**Soluci√≥n:**
```bash
# Verificar que el virtual environment est√° activado
# Debe aparecer (venv) al inicio de la l√≠nea de comando

# Si no est√° activado:
.\venv\Scripts\Activate.ps1  # Windows PowerShell
# o
venv\Scripts\activate.bat     # Windows CMD
# o
source venv/bin/activate      # Linux/Mac

# Reinstalar dependencias
pip install -r requirements.txt
```

---

### **Problema 2: "No such file or directory: data/01_raw/..."**

**Causa:** Los datos raw no est√°n incluidos en el repositorio (son muy grandes)

**Soluci√≥n:**
Los datos raw deben descargarse por separado. El proyecto incluye datasets de ejemplo en `.gitkeep` para mantener la estructura.

Para ejecutar con datos reales, coloca los CSV en:
```
data/01_raw/
‚îú‚îÄ‚îÄ LeagueofLegends.csv
‚îú‚îÄ‚îÄ matchinfo.csv
‚îú‚îÄ‚îÄ bans.csv
‚îú‚îÄ‚îÄ gold.csv
‚îú‚îÄ‚îÄ kills.csv
‚îú‚îÄ‚îÄ monsters.csv
‚îî‚îÄ‚îÄ structures.csv
```

---

### **Problema 3: Docker no inicia / Puerto 8080 ocupado**

**Soluci√≥n:**
```powershell
# Verificar que Docker Desktop est√° corriendo
docker --version

# Verificar servicios
docker-compose ps

# Si el puerto 8080 est√° ocupado
netstat -ano | findstr :8080
# Matar el proceso que lo usa o cambiar el puerto en docker-compose.yml
```

---

### **Problema 4: "Pipeline input not found in DataCatalog"**

**Soluci√≥n:**
```bash
# Verificar que el cat√°logo est√° bien configurado
kedro catalog list

# Limpiar cache de Kedro
kedro clean

# Verificar que los datos existen
dir data/01_raw/
```

---

### **Problema 5: Kedro tarda mucho / No responde**

**Soluci√≥n:**
```bash
# Ejecutar con modo async para mejor performance
kedro run --async

# O ejecutar un pipeline m√°s peque√±o primero
kedro run --pipeline data_cleaning
```

---

### **Problema 6: Error de permisos en Windows**

**Soluci√≥n:**
```powershell
# Ejecutar PowerShell como Administrador
# Right-click PowerShell ‚Üí "Run as Administrator"

# Permitir ejecuci√≥n de scripts
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

---

## üìû Comandos √ötiles de Referencia

### **Kedro:**
```bash
# Ver versi√≥n
kedro --version

# Ver ayuda
kedro --help

# Listar pipelines
kedro registry list

# Listar datasets
kedro catalog list

# Ejecutar pipeline espec√≠fico
kedro run --pipeline NOMBRE_PIPELINE

# Ejecutar desde un nodo
kedro run --from-nodes NOMBRE_NODO

# Ejecutar hasta un nodo
kedro run --to-nodes NOMBRE_NODO

# Ver visualizaci√≥n del pipeline (si kedro-viz est√° instalado)
kedro viz
```

### **Docker:**
```bash
# Ver servicios corriendo
docker-compose ps

# Ver logs
docker-compose logs

# Ver logs en tiempo real
docker-compose logs -f

# Ver logs de un servicio espec√≠fico
docker-compose logs airflow-scheduler

# Reiniciar servicios
docker-compose restart

# Detener servicios
docker-compose down

# Construir im√°genes
docker-compose build

# Ver im√°genes
docker images
```

### **Git:**
```bash
# Ver estado
git status

# Ver historial
git log --oneline

# Ver remoto
git remote -v

# Actualizar desde GitHub
git pull origin main
```

---

## üéì Estructura del Proyecto

```
league-project/
‚îú‚îÄ‚îÄ data/                          # Datos y resultados
‚îÇ   ‚îú‚îÄ‚îÄ 01_raw/                   # Datos originales
‚îÇ   ‚îú‚îÄ‚îÄ 02_intermediate/          # Datos limpios
‚îÇ   ‚îú‚îÄ‚îÄ 05_model_input/           # Features procesadas
‚îÇ   ‚îú‚îÄ‚îÄ 06_models/                # Modelos entrenados
‚îÇ   ‚îî‚îÄ‚îÄ 08_reporting/             # Reportes y m√©tricas
‚îú‚îÄ‚îÄ src/league_project/           # C√≥digo fuente
‚îÇ   ‚îî‚îÄ‚îÄ pipelines/                # 5 pipelines
‚îÇ       ‚îú‚îÄ‚îÄ data_cleaning/        # Limpieza de datos
‚îÇ       ‚îú‚îÄ‚îÄ data_exploration/     # An√°lisis exploratorio
‚îÇ       ‚îú‚îÄ‚îÄ data_processing/      # Feature engineering
‚îÇ       ‚îú‚îÄ‚îÄ data_science/         # Entrenamiento
‚îÇ       ‚îî‚îÄ‚îÄ evaluation/           # Evaluaci√≥n
‚îú‚îÄ‚îÄ conf/                         # Configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ base/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ catalog.yml          # Data catalog
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parameters.yml       # Par√°metros
‚îÇ   ‚îî‚îÄ‚îÄ logging.yml              # Logging config
‚îú‚îÄ‚îÄ airflow/                      # Apache Airflow
‚îÇ   ‚îî‚îÄ‚îÄ dags/                    # 3 DAGs
‚îú‚îÄ‚îÄ notebooks/                    # Jupyter notebooks
‚îú‚îÄ‚îÄ Dockerfile                    # Imagen Docker de Kedro
‚îú‚îÄ‚îÄ Dockerfile.airflow           # Imagen Docker de Airflow
‚îú‚îÄ‚îÄ docker-compose.yml           # Orquestaci√≥n
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias Python
‚îî‚îÄ‚îÄ pyproject.toml              # Configuraci√≥n del proyecto
```

---

## üìö Documentaci√≥n Adicional

- `README.md` - Descripci√≥n general del proyecto
- `GUIA_PRESENTACION.md` - Script para presentaci√≥n oral
- `README_COMPLETO.md` - Documentaci√≥n t√©cnica exhaustiva
- `EVALUACION_PARCIAL_CUMPLIMIENTO.md` - Verificaci√≥n de requisitos
- `DOCKER_AIRFLOW_GUIDE.md` - Gu√≠a detallada de Docker/Airflow
- `QUICK_START.md` - Inicio r√°pido en 5 minutos

---

## ‚úÖ Checklist de Verificaci√≥n

Despu√©s de ejecutar, verifica que:

- [ ] El pipeline se ejecut√≥ sin errores
- [ ] Se generaron reportes en `data/08_reporting/`
- [ ] Se crearon modelos en `data/06_models/`
- [ ] Los logs muestran "Pipeline execution completed successfully"
- [ ] Las m√©tricas de accuracy son > 95%
- [ ] El R¬≤ de regresi√≥n es > 0.75

---

## üéØ Resumen de Ejecuci√≥n R√°pida

**Para evaluadores con poco tiempo:**

```bash
# 1. Clonar
git clone https://github.com/glYohanny/Evaluacion_machine_learning.git
cd Evaluacion_machine_learning/league-project

# 2. Setup
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt

# 3. Ejecutar (1 comando)
kedro run

# 4. Ver resultados
dir data\08_reporting\
```

**Duraci√≥n total:** ~5 minutos

---

## üèÜ Resultados Esperados

Al finalizar la ejecuci√≥n completa, tendr√°s:

1. ‚úÖ **7 datasets limpios** sin duplicados ni outliers
2. ‚úÖ **8 reportes de an√°lisis** exploratorio
3. ‚úÖ **18 features** ingenieradas
4. ‚úÖ **10 modelos** de ML entrenados
5. ‚úÖ **M√©tricas completas**: 98.56% accuracy, R¬≤ 0.7928
6. ‚úÖ **Feature importance** identificada
7. ‚úÖ **Reportes JSON/CSV** listos para visualizaci√≥n

---

## üìß Contacto y Soporte

**Autor:** Pedro Torres (glYohanny)  
**Email:** ped.torres@duocuc.cl  
**GitHub:** https://github.com/glYohanny/Evaluacion_machine_learning  
**Curso:** Machine Learning - MLY0100  
**Instituci√≥n:** DuocUC

---

## üìÑ Licencia

Este proyecto es parte de un trabajo acad√©mico para el curso de Machine Learning.

---

**√öltima actualizaci√≥n:** Octubre 27, 2025  
**Versi√≥n:** 1.0.0  
**Estado:** ‚úÖ Production Ready

