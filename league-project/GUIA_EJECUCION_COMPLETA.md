# ğŸš€ GuÃ­a Completa de EjecuciÃ³n - League of Legends ML Project

**Autor:** Pedro Torres (glYohanny)  
**Email:** ped.torres@duocuc.cl  
**Repositorio:** https://github.com/glYohanny/Evaluacion_machine_learning

---

## ğŸ“‹ Tabla de Contenidos

1. [Requisitos Previos](#requisitos-previos)
2. [InstalaciÃ³n](#instalaciÃ³n)
3. [OpciÃ³n 1: EjecuciÃ³n con Kedro (Recomendado)](#opciÃ³n-1-ejecuciÃ³n-con-kedro-recomendado)
4. [OpciÃ³n 2: EjecuciÃ³n con Docker + Airflow](#opciÃ³n-2-ejecuciÃ³n-con-docker--airflow)
5. [Ver Resultados](#ver-resultados)
6. [Troubleshooting](#troubleshooting)

---

## ğŸ”§ Requisitos Previos

### **Software Necesario:**

1. **Python 3.11** (o superior)
   - Descargar: https://www.python.org/downloads/
   - Verificar: `python --version`

2. **Git** (para clonar el repositorio)
   - Descargar: https://git-scm.com/downloads
   - Verificar: `git --version`

3. **Docker Desktop** (OPCIONAL - solo para Airflow)
   - Descargar: https://www.docker.com/products/docker-desktop
   - Verificar: `docker --version`

### **Hardware Recomendado:**
- RAM: 8GB mÃ­nimo (16GB recomendado)
- Disco: 2GB libres
- CPU: 4 cores o mÃ¡s

---

## ğŸ“¥ InstalaciÃ³n

### **Paso 1: Clonar el Repositorio**

```bash
# Clonar el proyecto
git clone https://github.com/glYohanny/Evaluacion_machine_learning.git

# Navegar a la carpeta del proyecto
cd Evaluacion_machine_learning/league-project
```

### **Paso 2: Crear Virtual Environment**

**En Windows (PowerShell):**
```powershell
# Crear virtual environment
python -m venv venv

# Activar
.\venv\Scripts\Activate.ps1
```

**En Windows (CMD):**
```cmd
# Crear virtual environment
python -m venv venv

# Activar
venv\Scripts\activate.bat
```

**En Linux/Mac:**
```bash
# Crear virtual environment
python -m venv venv

# Activar
source venv/bin/activate
```

### **Paso 3: Instalar Dependencias**

```bash
# Actualizar pip
pip install --upgrade pip

# Instalar todas las dependencias
pip install -r requirements.txt
```

**DuraciÃ³n:** 2-3 minutos

### **Paso 4: Verificar InstalaciÃ³n**

```bash
# Verificar que Kedro estÃ¡ instalado
kedro --version

# DeberÃ­a mostrar: kedro, version 1.0.0 (o similar)
```

---

## ğŸ¯ OpciÃ³n 1: EjecuciÃ³n con Kedro (Recomendado)

Esta es la forma **MÃS RÃPIDA y SIMPLE** de ejecutar el proyecto.

### **A. Pipeline Completo (Recomendado)**

Ejecuta TODO el sistema de ML de principio a fin:

```bash
kedro run
```

**Â¿QuÃ© hace?**
1. âœ… Limpia 7 datasets raw
2. âœ… Realiza anÃ¡lisis exploratorio completo
3. âœ… Crea 18 features ingenieradas
4. âœ… Entrena 10 modelos de ML
5. âœ… EvalÃºa con mÃ©tricas completas

**DuraciÃ³n:** ~1-2 minutos  
**Output esperado:**
```
[INFO] Pipeline execution completed successfully in XX.X sec.
[INFO] Completed 33 out of 33 tasks
```

---

### **B. Pipelines Individuales**

Ejecuta partes especÃ­ficas del sistema:

#### **1. Solo Limpieza de Datos**
```bash
kedro run --pipeline data_cleaning
```
**DuraciÃ³n:** ~15 segundos  
**Output:** Datasets limpios en `data/02_intermediate/`

#### **2. Solo AnÃ¡lisis Exploratorio (EDA)**
```bash
kedro run --pipeline data_exploration
```
**DuraciÃ³n:** ~30 segundos  
**Output:** Reportes CSV en `data/08_reporting/`

#### **3. Limpieza + EDA (Recomendado para Demo RÃ¡pida)**
```bash
kedro run --pipeline eda
```
**DuraciÃ³n:** ~45 segundos  
**Output:** Datos limpios + 8 reportes de anÃ¡lisis

#### **4. Feature Engineering**
```bash
kedro run --pipeline data_processing
```
**DuraciÃ³n:** ~20 segundos  
**Output:** Features en `data/05_model_input/`

#### **5. Entrenamiento de Modelos**
```bash
kedro run --pipeline data_science
```
**DuraciÃ³n:** ~30 segundos  
**Output:** 10 modelos en `data/06_models/`

#### **6. EvaluaciÃ³n de Modelos**
```bash
kedro run --pipeline evaluation
```
**DuraciÃ³n:** ~10 segundos  
**Output:** MÃ©tricas en `data/08_reporting/`

---

### **C. Ver CatÃ¡logo de Datos**

```bash
# Listar todos los datasets disponibles
kedro catalog list

# Ver estructura de un pipeline especÃ­fico
kedro catalog ds --pipeline data_cleaning
```

---

### **D. Ver Pipelines Disponibles**

```bash
# Listar todos los pipelines
kedro registry list
```

**Output esperado:**
```
- data_cleaning
- data_exploration
- data_processing
- data_science
- evaluation
- eda (combinado)
- __default__ (completo)
```

---

## ğŸ³ OpciÃ³n 2: EjecuciÃ³n con Docker + Airflow

Esta opciÃ³n es mÃ¡s avanzada y muestra el sistema en **producciÃ³n**.

### **Requisitos:**
- Docker Desktop instalado y corriendo
- 8GB RAM disponible

---

### **A. Setup Inicial (Solo Primera Vez)**

```powershell
# 1. Navegar a la carpeta del proyecto
cd league-project

# 2. Ejecutar script de setup
.\setup_airflow_windows.ps1
```

**Â¿QuÃ© hace este script?**
1. âœ… Verifica Docker Desktop
2. âœ… Crea archivo `.env`
3. âœ… Crea directorios de Airflow
4. âœ… Construye imagen Docker con Kedro
5. âœ… Inicializa base de datos de Airflow

**DuraciÃ³n:** 10-15 minutos (primera vez)

---

### **B. Iniciar Servicios**

```powershell
# Levantar todos los servicios
docker-compose up -d
```

**Â¿QuÃ© se inicia?**
- PostgreSQL (base de datos)
- Redis (message broker)
- Airflow Webserver (UI)
- Airflow Scheduler (orquestador)
- AplicaciÃ³n Kedro

**DuraciÃ³n:** 30-60 segundos

---

### **C. Acceder a Airflow UI**

1. Abre navegador: http://localhost:8080
2. Login:
   - **Usuario:** `admin`
   - **Password:** `admin`

---

### **D. Ejecutar Pipelines en Airflow**

#### **DAG 1: kedro_eda_pipeline (AnÃ¡lisis Exploratorio)**

**Schedule:** Diario (@daily)

**Pasos:**
1. En la UI de Airflow, busca `kedro_eda_pipeline`
2. Click en el botÃ³n **â–¶ï¸ azul** (Trigger DAG)
3. Confirma "Trigger"
4. Click en el nombre del DAG para ver progreso
5. Ve a **"Graph View"** para ver el flujo

**DuraciÃ³n:** ~3 minutos

**Tareas que ejecuta:**
- Clean 7 datasets
- Analyze teams (246 equipos)
- Analyze champions (137 campeones)
- Analyze correlations
- Generate reports

---

#### **DAG 2: kedro_league_ml_pipeline (Pipeline Completo)**

**Schedule:** Semanal (@weekly)

**Pasos:**
1. Click en `kedro_league_ml_pipeline`
2. Click en **â–¶ï¸ Trigger DAG**
3. Ve a **"Graph View"**

**DuraciÃ³n:** ~15 minutos

**Tareas que ejecuta:**
1. data_cleaning
2. data_exploration
3. data_processing
4. model_training (10 modelos)
5. model_evaluation
6. generate_final_report

---

#### **DAG 3: kedro_model_training_pipeline (Solo Modelos)**

**Schedule:** Manual (None)

**Para quÃ© sirve:** Reentrenar modelos sin reprocesar datos

**Pasos:**
1. Click en `kedro_model_training_pipeline`
2. Click en **â–¶ï¸ Trigger DAG**

**DuraciÃ³n:** ~8 minutos

---

### **E. Ver Logs en Airflow**

1. Click en cualquier tarea (caja verde/amarilla/roja)
2. Click en **"Log"**
3. VerÃ¡s el output completo de Kedro

---

### **F. Detener Servicios**

```powershell
# Detener todos los servicios
docker-compose down

# Detener y eliminar volÃºmenes (limpieza completa)
docker-compose down -v
```

---

## ğŸ“Š Ver Resultados

### **1. Reportes de AnÃ¡lisis Exploratorio**

```bash
# Listar todos los reportes
dir data/08_reporting/

# Ver estadÃ­sticas descriptivas
type data/08_reporting/descriptive_statistics.csv

# Ver anÃ¡lisis de equipos
type data/08_reporting/team_performance_analysis.csv

# Ver anÃ¡lisis de campeones
type data/08_reporting/champion_bans_analysis.csv
```

**Reportes generados:**
- `descriptive_statistics.csv` - EstadÃ­sticas bÃ¡sicas
- `team_performance_analysis.csv` - 246 equipos analizados
- `champion_bans_analysis.csv` - 137 campeones
- `neutral_objectives_analysis.csv` - Dragones, Barones
- `structures_analysis.csv` - Torres, Inhibidores
- `correlations_analysis.csv` - Matriz de correlaciÃ³n
- `game_duration_analysis.csv` - AnÃ¡lisis temporal
- `data_quality_report.csv` - Calidad de datos
- `eda_complete_report.json` - Reporte consolidado

---

### **2. MÃ©tricas de Modelos**

```bash
# Ver mÃ©tricas de clasificaciÃ³n
type data/08_reporting/classification_metrics.parquet

# Ver mÃ©tricas de regresiÃ³n
type data/08_reporting/regression_metrics.parquet

# Ver reporte completo de clasificaciÃ³n
type data/08_reporting/classification_report.json

# Ver reporte completo de regresiÃ³n
type data/08_reporting/regression_report.json
```

---

### **3. Modelos Entrenados**

```bash
# Listar modelos guardados
dir data/06_models/

# DeberÃ­as ver 10 archivos .pkl:
# - linear_regression.pkl
# - ridge_regression.pkl
# - lasso_regression.pkl
# - random_forest_regressor.pkl
# - gradient_boosting_regressor.pkl
# - logistic_regression.pkl
# - random_forest_classifier.pkl
# - gradient_boosting_classifier.pkl
# - svm.pkl
# - naive_bayes.pkl
```

---

### **4. Resultados Esperados**

#### **ClasificaciÃ³n (PredicciÃ³n de Ganador):**

| Modelo | Accuracy | F1-Score | AUC-ROC |
|--------|----------|----------|---------|
| **SVM** ğŸ¥‡ | **98.56%** | **0.9868** | **0.9988** |
| Logistic Regression | 98.36% | 0.9851 | 0.9991 |
| Random Forest | 98.23% | 0.9838 | 0.9988 |
| Gradient Boosting | 98.16% | 0.9832 | 0.9990 |
| Naive Bayes | 97.05% | 0.9729 | 0.9895 |

**ğŸ† Mejor Modelo:** SVM con 98.56% accuracy

---

#### **RegresiÃ³n (PredicciÃ³n de DuraciÃ³n):**

| Modelo | RMSE | MAE | RÂ² |
|--------|------|-----|-----|
| **Gradient Boosting** ğŸ¥‡ | **3.70** | **2.85** | **0.7928** |
| Ridge | 3.95 | 3.08 | 0.7634 |
| Linear Regression | 3.95 | 3.08 | 0.7633 |
| Random Forest | 3.96 | 3.02 | 0.7624 |
| Lasso | 3.97 | 3.10 | 0.7610 |

**ğŸ† Mejor Modelo:** Gradient Boosting con RÂ² 0.7928

---

## ğŸ” Troubleshooting

### **Problema 1: "ModuleNotFoundError: No module named 'kedro'"**

**SoluciÃ³n:**
```bash
# Verificar que el virtual environment estÃ¡ activado
# Debe aparecer (venv) al inicio de la lÃ­nea de comando

# Si no estÃ¡ activado:
.\venv\Scripts\Activate.ps1  # Windows PowerShell
# o
venv\Scripts\activate.bat     # Windows CMD
# o
source venv/bin/activate      # Linux/Mac

# Reinstalar dependencias
pip install -r requirements.txt
```

---

### **Problema 2: "No such file or directory: data/01_raw/..."**

**Causa:** Los datos raw no estÃ¡n incluidos en el repositorio (son muy grandes)

**SoluciÃ³n:**
Los datos raw deben descargarse por separado. El proyecto incluye datasets de ejemplo en `.gitkeep` para mantener la estructura.

Para ejecutar con datos reales, coloca los CSV en:
```
data/01_raw/
â”œâ”€â”€ LeagueofLegends.csv
â”œâ”€â”€ matchinfo.csv
â”œâ”€â”€ bans.csv
â”œâ”€â”€ gold.csv
â”œâ”€â”€ kills.csv
â”œâ”€â”€ monsters.csv
â””â”€â”€ structures.csv
```

---

### **Problema 3: Docker no inicia / Puerto 8080 ocupado**

**SoluciÃ³n:**
```powershell
# Verificar que Docker Desktop estÃ¡ corriendo
docker --version

# Verificar servicios
docker-compose ps

# Si el puerto 8080 estÃ¡ ocupado
netstat -ano | findstr :8080
# Matar el proceso que lo usa o cambiar el puerto en docker-compose.yml
```

---

### **Problema 4: "Pipeline input not found in DataCatalog"**

**SoluciÃ³n:**
```bash
# Verificar que el catÃ¡logo estÃ¡ bien configurado
kedro catalog list

# Limpiar cache de Kedro
kedro clean

# Verificar que los datos existen
dir data/01_raw/
```

---

### **Problema 5: Kedro tarda mucho / No responde**

**SoluciÃ³n:**
```bash
# Ejecutar con modo async para mejor performance
kedro run --async

# O ejecutar un pipeline mÃ¡s pequeÃ±o primero
kedro run --pipeline data_cleaning
```

---

### **Problema 6: Error de permisos en Windows**

**SoluciÃ³n:**
```powershell
# Ejecutar PowerShell como Administrador
# Right-click PowerShell â†’ "Run as Administrator"

# Permitir ejecuciÃ³n de scripts
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

---

## ğŸ“ Comandos Ãštiles de Referencia

### **Kedro:**
```bash
# Ver versiÃ³n
kedro --version

# Ver ayuda
kedro --help

# Listar pipelines
kedro registry list

# Listar datasets
kedro catalog list

# Ejecutar pipeline especÃ­fico
kedro run --pipeline NOMBRE_PIPELINE

# Ejecutar desde un nodo
kedro run --from-nodes NOMBRE_NODO

# Ejecutar hasta un nodo
kedro run --to-nodes NOMBRE_NODO

# Ver visualizaciÃ³n del pipeline (si kedro-viz estÃ¡ instalado)
kedro viz
```

### **Docker:**
```bash
# Ver servicios corriendo
docker-compose ps

# Ver logs
docker-compose logs

# Ver logs en tiempo real
docker-compose logs -f

# Ver logs de un servicio especÃ­fico
docker-compose logs airflow-scheduler

# Reiniciar servicios
docker-compose restart

# Detener servicios
docker-compose down

# Construir imÃ¡genes
docker-compose build

# Ver imÃ¡genes
docker images
```

### **Git:**
```bash
# Ver estado
git status

# Ver historial
git log --oneline

# Ver remoto
git remote -v

# Actualizar desde GitHub
git pull origin main
```

---

## ğŸ“ Estructura del Proyecto

```
league-project/
â”œâ”€â”€ data/                          # Datos y resultados
â”‚   â”œâ”€â”€ 01_raw/                   # Datos originales
â”‚   â”œâ”€â”€ 02_intermediate/          # Datos limpios
â”‚   â”œâ”€â”€ 05_model_input/           # Features procesadas
â”‚   â”œâ”€â”€ 06_models/                # Modelos entrenados
â”‚   â””â”€â”€ 08_reporting/             # Reportes y mÃ©tricas
â”œâ”€â”€ src/league_project/           # CÃ³digo fuente
â”‚   â””â”€â”€ pipelines/                # 5 pipelines
â”‚       â”œâ”€â”€ data_cleaning/        # Limpieza de datos
â”‚       â”œâ”€â”€ data_exploration/     # AnÃ¡lisis exploratorio
â”‚       â”œâ”€â”€ data_processing/      # Feature engineering
â”‚       â”œâ”€â”€ data_science/         # Entrenamiento
â”‚       â””â”€â”€ evaluation/           # EvaluaciÃ³n
â”œâ”€â”€ conf/                         # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ catalog.yml          # Data catalog
â”‚   â”‚   â””â”€â”€ parameters.yml       # ParÃ¡metros
â”‚   â””â”€â”€ logging.yml              # Logging config
â”œâ”€â”€ airflow/                      # Apache Airflow
â”‚   â””â”€â”€ dags/                    # 3 DAGs
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”œâ”€â”€ Dockerfile                    # Imagen Docker de Kedro
â”œâ”€â”€ Dockerfile.airflow           # Imagen Docker de Airflow
â”œâ”€â”€ docker-compose.yml           # OrquestaciÃ³n
â”œâ”€â”€ requirements.txt             # Dependencias Python
â””â”€â”€ pyproject.toml              # ConfiguraciÃ³n del proyecto
```

---

## ğŸ“š DocumentaciÃ³n Adicional

- `README.md` - DescripciÃ³n general del proyecto
- `GUIA_PRESENTACION.md` - Script para presentaciÃ³n oral
- `README_COMPLETO.md` - DocumentaciÃ³n tÃ©cnica exhaustiva
- `EVALUACION_PARCIAL_CUMPLIMIENTO.md` - VerificaciÃ³n de requisitos
- `DOCKER_AIRFLOW_GUIDE.md` - GuÃ­a detallada de Docker/Airflow
- `QUICK_START.md` - Inicio rÃ¡pido en 5 minutos

---

## âœ… Checklist de VerificaciÃ³n

DespuÃ©s de ejecutar, verifica que:

- [ ] El pipeline se ejecutÃ³ sin errores
- [ ] Se generaron reportes en `data/08_reporting/`
- [ ] Se crearon modelos en `data/06_models/`
- [ ] Los logs muestran "Pipeline execution completed successfully"
- [ ] Las mÃ©tricas de accuracy son > 95%
- [ ] El RÂ² de regresiÃ³n es > 0.75

---

## ğŸ¯ Resumen de EjecuciÃ³n RÃ¡pida

**Para evaluadores con poco tiempo:**

```bash
# 1. Clonar
git clone https://github.com/glYohanny/Evaluacion_machine_learning.git
cd Evaluacion_machine_learning/league-project

# 2. Setup
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt

# 3. Ejecutar (1 comando)
kedro run

# 4. Ver resultados
dir data\08_reporting\
```

**DuraciÃ³n total:** ~5 minutos

---

## ğŸ† Resultados Esperados

Al finalizar la ejecuciÃ³n completa, tendrÃ¡s:

1. âœ… **7 datasets limpios** sin duplicados ni outliers
2. âœ… **8 reportes de anÃ¡lisis** exploratorio
3. âœ… **18 features** ingenieradas
4. âœ… **10 modelos** de ML entrenados
5. âœ… **MÃ©tricas completas**: 98.56% accuracy, RÂ² 0.7928
6. âœ… **Feature importance** identificada
7. âœ… **Reportes JSON/CSV** listos para visualizaciÃ³n

---

## ğŸ“§ Contacto y Soporte

**Autor:** Pedro Torres (glYohanny)  
**Email:** ped.torres@duocuc.cl  
**GitHub:** https://github.com/glYohanny/Evaluacion_machine_learning  
**Curso:** Machine Learning - MLY0100  
**InstituciÃ³n:** DuocUC

---

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico para el curso de Machine Learning.

---

**Ãšltima actualizaciÃ³n:** Octubre 27, 2025  
**VersiÃ³n:** 1.0.0  
**Estado:** âœ… Production Ready

