# üìä Informe Final Acad√©mico - Proyecto de Machine Learning

**Curso:** MLY0100 - Machine Learning  
**Instituci√≥n:** DuocUC  
**Autor:** Pedro Torres (glYohanny)  
**Email:** ped.torres@duocuc.cl  
**Fecha:** Octubre 27, 2025  
**Repositorio:** https://github.com/glYohanny/Evaluacion_machine_learning

---

## Resumen Ejecutivo

Este proyecto implementa un sistema completo de Machine Learning para an√°lisis y predicci√≥n de partidas del torneo mundial de League of Legends (Worlds). Se desarroll√≥ siguiendo la metodolog√≠a CRISP-DM, utilizando Kedro como framework de pipelines, Docker para containerizaci√≥n y Apache Airflow para orquestaci√≥n. Los resultados obtenidos fueron excepcionales: **98.56% de accuracy** en predicci√≥n de ganador y **R¬≤ de 0.7928** en predicci√≥n de duraci√≥n de partidas.

---

## 1. Introducci√≥n

### 1.1 Contexto del Proyecto

League of Legends es uno de los videojuegos competitivos m√°s populares del mundo, con torneos profesionales que atraen millones de espectadores. El torneo mundial (Worlds) representa el pin√°culo de la competici√≥n profesional, donde los mejores equipos del mundo compiten por el campeonato.

### 1.2 Problem√°tica

Los analistas deportivos y equipos profesionales necesitan herramientas para:
- Predecir el resultado de las partidas bas√°ndose en estad√≠sticas tempranas
- Estimar la duraci√≥n de las partidas para planificaci√≥n de torneos
- Identificar los factores m√°s importantes que contribuyen a la victoria

### 1.3 Objetivos del Proyecto

#### Objetivo General:
Desarrollar un sistema de Machine Learning para an√°lisis y predicci√≥n de partidas profesionales de League of Legends.

#### Objetivos Espec√≠ficos:
1. Implementar un pipeline completo de datos utilizando Kedro
2. Entrenar y comparar m√∫ltiples modelos de ML (regresi√≥n y clasificaci√≥n)
3. Identificar las features m√°s importantes para la predicci√≥n
4. Desplegar el sistema usando Docker y Apache Airflow
5. Documentar el proceso completo siguiendo CRISP-DM

---

## 2. Metodolog√≠a CRISP-DM

### 2.1 Business Understanding

**Preguntas de negocio:**
1. ¬øQu√© factores determinan el ganador de una partida?
2. ¬øSe puede predecir la duraci√≥n de una partida con precisi√≥n?
3. ¬øCu√°les son las m√©tricas m√°s importantes para el √©xito?

**Criterios de √©xito:**
- Accuracy > 90% para predicci√≥n de ganador
- R¬≤ > 0.75 para predicci√≥n de duraci√≥n
- Sistema deployable en producci√≥n

### 2.2 Data Understanding

**Dataset utilizado:**
- **Fuente:** Partidas profesionales del torneo Worlds
- **Tama√±o:** 7,620 partidas
- **Per√≠odo:** M√∫ltiples temporadas
- **Equipos:** 246 equipos profesionales
- **Campeones:** 137 personajes √∫nicos

**Estructura de datos:**
- 7 archivos CSV relacionados
- Variables: kills, gold, torres, objetivos neutrales, bans
- Target variables: resultado de partida (binario), duraci√≥n (continuo)

**An√°lisis exploratorio realizado:**
- Estad√≠sticas descriptivas completas
- An√°lisis de distribuciones
- Identificaci√≥n de outliers
- Matriz de correlaciones
- An√°lisis por equipos y campeones

### 2.3 Data Preparation

**Limpieza de datos:**
- Eliminaci√≥n de 122 registros duplicados
- Imputaci√≥n de 423 valores faltantes usando moda
- Detecci√≥n y tratamiento de 7,611 outliers usando m√©todo IQR
- Validaci√≥n de tipos de datos

**Feature Engineering:**
Se crearon 18 features derivadas, incluyendo:
- `gold_diff`: Diferencia de oro entre equipos
- `kills_diff`: Diferencia de asesinatos
- `towers_diff`: Diferencia de torres destruidas
- `dragons_diff`: Diferencia de dragones capturados
- `barons_diff`: Diferencia de barones capturados

**Transformaciones:**
- Normalizaci√≥n con StandardScaler
- Train/test split: 80/20 (6,096 train, 1,524 test)
- Conversi√≥n a formato Parquet para eficiencia

### 2.4 Modeling

**Modelos de Regresi√≥n (Predicci√≥n de Duraci√≥n):**
1. Linear Regression (baseline)
2. Ridge Regression (regularizaci√≥n L2)
3. Lasso Regression (regularizaci√≥n L1)
4. Random Forest Regressor
5. Gradient Boosting Regressor

**Modelos de Clasificaci√≥n (Predicci√≥n de Ganador):**
1. Logistic Regression (baseline)
2. Random Forest Classifier
3. Gradient Boosting Classifier
4. Support Vector Machine (SVM)
5. Naive Bayes

**Configuraci√≥n:**
- Todos los modelos utilizan configuraciones est√°ndar de scikit-learn
- Random state = 42 para reproducibilidad
- Train/test split consistente para todos los modelos

### 2.5 Evaluation

**M√©tricas de Regresi√≥n:**
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- R¬≤ (Coeficiente de Determinaci√≥n)
- Comparaci√≥n Train vs Test para detectar overfitting

**M√©tricas de Clasificaci√≥n:**
- Accuracy
- Precision
- Recall
- F1-Score
- AUC-ROC
- Matriz de confusi√≥n

### 2.6 Deployment

**Infraestructura implementada:**
- Kedro: Framework de pipelines modulares
- Docker: Containerizaci√≥n del sistema
- Apache Airflow: Orquestaci√≥n y scheduling
- PostgreSQL: Base de datos de metadatos
- Redis: Message broker

**Automatizaci√≥n:**
- 3 DAGs de Airflow configurados
- Scheduling diario para EDA
- Scheduling semanal para reentrenamiento
- Ejecuci√≥n manual para experimentaci√≥n

---

## 3. Resultados

### 3.1 Modelos de Clasificaci√≥n

**Tabla de Resultados:**

| Modelo | Accuracy | Precision | Recall | F1-Score | AUC-ROC | Train Acc |
|--------|----------|-----------|--------|----------|---------|-----------|
| **SVM** | **0.9856** | **0.9856** | **0.9880** | **0.9868** | **0.9988** | 0.9916 |
| Logistic Regression | 0.9836 | 0.9810 | 0.9892 | 0.9851 | 0.9991 | 0.9882 |
| Random Forest | 0.9823 | 0.9821 | 0.9856 | 0.9838 | 0.9988 | 1.0000 |
| Gradient Boosting | 0.9816 | 0.9832 | 0.9832 | 0.9832 | 0.9990 | 0.9944 |
| Naive Bayes | 0.9705 | 0.9747 | 0.9712 | 0.9729 | 0.9895 | 0.9728 |

**Mejor modelo:** SVM con 98.56% de accuracy

**Interpretaci√≥n:**
- El modelo SVM predice correctamente el ganador en 98.56 de cada 100 partidas
- El F1-Score de 0.9868 indica un excelente balance entre precision y recall
- El AUC-ROC de 0.9988 demuestra capacidad casi perfecta de discriminaci√≥n
- No se observa overfitting significativo (train accuracy 99.16% vs test 98.56%)

### 3.2 Modelos de Regresi√≥n

**Tabla de Resultados:**

| Modelo | RMSE Train | RMSE Test | MAE Train | MAE Test | R¬≤ Train | R¬≤ Test |
|--------|------------|-----------|-----------|----------|----------|---------|
| **Gradient Boosting** | **3.44** | **3.70** | **2.68** | **2.85** | **0.8123** | **0.7928** |
| Ridge | 3.95 | 3.95 | 3.09 | 3.08 | 0.7525 | 0.7634 |
| Linear Regression | 3.95 | 3.95 | 3.09 | 3.08 | 0.7525 | 0.7633 |
| Random Forest | 1.86 | 3.96 | 1.44 | 3.02 | 0.9450 | 0.7624 |
| Lasso | 3.97 | 3.97 | 3.10 | 3.10 | 0.7503 | 0.7610 |

**Mejor modelo:** Gradient Boosting con R¬≤ de 0.7928

**Interpretaci√≥n:**
- El modelo explica el 79.28% de la varianza en la duraci√≥n de partidas
- El error promedio (MAE) es de 2.85 minutos
- Considerando que las partidas duran 25-45 minutos, un error de ~3 minutos es excelente
- Random Forest muestra overfitting (R¬≤ train 0.945 vs test 0.762)

### 3.3 Feature Importance

**Top 10 Features por Importancia:**

| Rank | Feature | Importancia (%) | Descripci√≥n |
|------|---------|-----------------|-------------|
| 1 | gold_diff | 35.2% | Diferencia de oro entre equipos |
| 2 | kills_diff | 28.7% | Diferencia de asesinatos |
| 3 | towers_diff | 18.4% | Diferencia de torres destruidas |
| 4 | dragons_diff | 7.3% | Diferencia de dragones capturados |
| 5 | barons_diff | 4.8% | Diferencia de barones capturados |
| 6 | blue_kills | 2.1% | Asesinatos del equipo azul |
| 7 | red_kills | 1.5% | Asesinatos del equipo rojo |
| 8 | gamelength_minutes | 1.2% | Duraci√≥n de la partida |
| 9 | blue_towers | 0.5% | Torres destruidas equipo azul |
| 10 | red_towers | 0.3% | Torres destruidas equipo rojo |

**Insights clave:**
- Las diferencias entre equipos son m√°s predictivas que valores absolutos
- El oro es el factor m√°s importante (35%), reflejando ventaja econ√≥mica
- Los kills son el segundo factor m√°s importante (29%), indicando dominio en combate
- Las estructuras (torres) tambi√©n son significativas (18%)

### 3.4 An√°lisis de Equipos

**Top 10 Equipos por Win Rate:**

| Equipo | Partidas | Victorias | Derrotas | Win Rate | Duraci√≥n Promedio |
|--------|----------|-----------|----------|----------|-------------------|
| T1 | 85 | 67 | 18 | 78.82% | 31.2 min |
| GEN | 78 | 59 | 19 | 75.64% | 32.1 min |
| JDG | 72 | 54 | 18 | 75.00% | 30.8 min |
| DK | 68 | 49 | 19 | 72.06% | 31.5 min |
| RNG | 65 | 46 | 19 | 70.77% | 32.8 min |

**Total equipos analizados:** 246

### 3.5 An√°lisis de Campeones

**Top 10 Campeones M√°s Baneados:**

| Campe√≥n | Bans Totales | % de Partidas | Correlaci√≥n con Victoria |
|---------|--------------|---------------|--------------------------|
| Zeri | 1,847 | 24.2% | +0.15 |
| Yuumi | 1,623 | 21.3% | +0.22 |
| Kalista | 1,456 | 19.1% | +0.18 |
| LeBlanc | 1,289 | 16.9% | +0.12 |
| Lucian | 1,145 | 15.0% | +0.14 |

**Total campeones analizados:** 137

---

## 4. An√°lisis y Discusi√≥n

### 4.1 Comparaci√≥n de Modelos

**Clasificaci√≥n:**
- **SVM** logr√≥ el mejor balance de m√©tricas
- Los modelos basados en √°rboles (RF, GB) tienen m√©tricas muy cercanas
- Naive Bayes, aunque m√°s simple, logra 97% accuracy
- **Conclusi√≥n:** SVM es el modelo recomendado para producci√≥n

**Regresi√≥n:**
- **Gradient Boosting** supera a otros modelos en R¬≤ test
- Random Forest muestra overfitting significativo
- Modelos lineales (Linear, Ridge, Lasso) tienen desempe√±o similar y robusto
- **Conclusi√≥n:** Gradient Boosting es el modelo recomendado, con Ridge como alternativa robusta

### 4.2 Factores de √âxito

Los tres factores m√°s importantes identificados son:

1. **Ventaja econ√≥mica (oro)**: El oro permite comprar mejores items, aumentando el poder del equipo
2. **Ventaja en combate (kills)**: Los kills otorgan oro y experiencia, creando ventaja compuesta
3. **Control del mapa (torres)**: Las torres permiten avanzar territorio y limitar opciones del enemigo

### 4.3 Limitaciones del Estudio

1. **Datos hist√≥ricos:** Solo incluye partidas profesionales, puede no generalizar a ranked
2. **Parches del juego:** Los cambios de balance pueden afectar la validez temporal de los modelos
3. **Factores cualitativos:** No captura habilidad individual, comunicaci√≥n de equipo, estrategia
4. **Sesgo de datos:** Posible sesgo hacia equipos m√°s exitosos (m√°s partidas en dataset)

### 4.4 Trabajo Futuro

**Mejoras potenciales:**

1. **Hyperparameter Tuning:**
   - GridSearchCV o RandomizedSearchCV
   - Optimizaci√≥n bayesiana
   - Potential improvement: +2-3% accuracy

2. **Cross-Validation:**
   - K-Fold CV (k=5 o k=10)
   - Validaci√≥n m√°s robusta
   - Reducir varianza de estimaci√≥n

3. **Deep Learning:**
   - Redes neuronales recurrentes (LSTM) para secuencias temporales
   - An√°lisis de progresi√≥n de partida minuto a minuto
   - Potential improvement: +5-8% accuracy

4. **Features adicionales:**
   - Composici√≥n de campeones (synergies)
   - M√©tricas de jugadores individuales
   - Contexto del torneo (BO1 vs BO5)

5. **Deployment avanzado:**
   - API REST para predicciones en tiempo real
   - Dashboard interactivo con Streamlit
   - Integraci√≥n con MLflow para tracking

---

## 5. Arquitectura del Sistema

### 5.1 Arquitectura de Software

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      APACHE AIRFLOW (Capa 3)        ‚îÇ
‚îÇ   ‚Ä¢ Orquestaci√≥n                    ‚îÇ
‚îÇ   ‚Ä¢ Scheduling                      ‚îÇ
‚îÇ   ‚Ä¢ Monitoreo                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     KEDRO PIPELINES (Capa 2)        ‚îÇ
‚îÇ   ‚Ä¢ data_cleaning (8 nodos)         ‚îÇ
‚îÇ   ‚Ä¢ data_exploration (8 nodos)      ‚îÇ
‚îÇ   ‚Ä¢ data_processing (7 nodos)       ‚îÇ
‚îÇ   ‚Ä¢ data_science (4 nodos)          ‚îÇ
‚îÇ   ‚Ä¢ evaluation (6 nodos)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   DOCKER CONTAINERS (Capa 1)        ‚îÇ
‚îÇ   ‚Ä¢ PostgreSQL                      ‚îÇ
‚îÇ   ‚Ä¢ Redis                           ‚îÇ
‚îÇ   ‚Ä¢ Kedro App                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.2 Pipelines Implementados

**Total:** 5 pipelines, 33 nodos

1. **data_cleaning (8 nodos):**
   - Limpieza de 7 datasets
   - Eliminaci√≥n de duplicados
   - Imputaci√≥n de nulos
   - Detecci√≥n de outliers
   - Generaci√≥n de reporte de calidad

2. **data_exploration (8 nodos):**
   - Estad√≠sticas descriptivas
   - An√°lisis de equipos (246)
   - An√°lisis de campeones (137)
   - Objetivos neutrales
   - Estructuras
   - Correlaciones
   - Duraci√≥n de partidas
   - Reporte consolidado

3. **data_processing (7 nodos):**
   - Agregaci√≥n de kills
   - Agregaci√≥n de monsters
   - Agregaci√≥n de structures
   - Agregaci√≥n de gold
   - Selecci√≥n de features
   - Split train/test
   - Normalizaci√≥n

4. **data_science (4 nodos):**
   - Entrenamiento regresi√≥n (5 modelos)
   - Entrenamiento clasificaci√≥n (5 modelos)
   - Predicciones regresi√≥n
   - Predicciones clasificaci√≥n

5. **evaluation (6 nodos):**
   - Evaluaci√≥n regresi√≥n
   - Evaluaci√≥n clasificaci√≥n
   - Feature importance regresi√≥n
   - Feature importance clasificaci√≥n
   - Reporte regresi√≥n
   - Reporte clasificaci√≥n

### 5.3 Tecnolog√≠as y Herramientas

| Categor√≠a | Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|-----------|------------|---------|-----------|
| Lenguaje | Python | 3.11 | Desarrollo principal |
| ML Framework | Kedro | 1.0.0 | Pipeline orchestration |
| ML Library | scikit-learn | 1.3+ | Modelos de ML |
| Data | Pandas | 2.0+ | Manipulaci√≥n de datos |
| Data | NumPy | 1.24+ | Operaciones num√©ricas |
| Containerization | Docker | 20.10+ | Empaquetado |
| Orchestration | Airflow | 2.8.0 | Automatizaci√≥n |
| Database | PostgreSQL | 15 | Metadatos |
| Message Broker | Redis | latest | Comunicaci√≥n |
| Visualization | Matplotlib | 3.7+ | Gr√°ficos |
| Visualization | Seaborn | 0.12+ | Gr√°ficos estad√≠sticos |
| Testing | pytest | 7.4+ | Tests unitarios |
| Linting | flake8 | 6.0+ | Calidad de c√≥digo |
| Formatting | black | 23.0+ | Formateo de c√≥digo |

---

## 6. Conclusiones

### 6.1 Logros del Proyecto

1. **Objetivos cumplidos al 100%:**
   - ‚úÖ Accuracy de clasificaci√≥n: 98.56% (objetivo: > 90%)
   - ‚úÖ R¬≤ de regresi√≥n: 0.7928 (objetivo: > 0.75)
   - ‚úÖ Sistema deployable en producci√≥n

2. **Implementaci√≥n profesional:**
   - Sistema modular con 5 pipelines
   - 33 nodos de procesamiento
   - Arquitectura de 3 capas (Docker, Kedro, Airflow)
   - Completamente automatizado

3. **Documentaci√≥n exhaustiva:**
   - 20+ documentos t√©cnicos
   - M√°s de 100 p√°ginas de documentaci√≥n
   - Gu√≠as paso a paso
   - Scripts de automatizaci√≥n

4. **Reproducibilidad:**
   - Dockerizado completamente
   - C√≥digo versionado en GitHub
   - Dependencias especificadas
   - Random state fijo (42)

### 6.2 Contribuciones

Este proyecto demuestra:

1. **Aplicaci√≥n pr√°ctica de CRISP-DM:** Implementaci√≥n completa end-to-end
2. **MLOps:** Integraci√≥n de ML con pr√°cticas de DevOps (Docker, CI/CD)
3. **Ingenier√≠a de datos:** Pipelines modulares y mantenibles
4. **Producci√≥n:** Sistema listo para deployment real

### 6.3 Aprendizajes Clave

1. **T√©cnicos:**
   - Kedro facilita la modularizaci√≥n de pipelines complejos
   - Docker garantiza reproducibilidad entre ambientes
   - Airflow permite automatizaci√≥n de workflows
   - Los modelos basados en √°rboles dominan en datos tabulares

2. **Metodol√≥gicos:**
   - CRISP-DM estructura efectivamente proyectos de ML
   - El 80% del tiempo se invierte en preparaci√≥n de datos
   - La documentaci√≥n es tan importante como el c√≥digo
   - El deployment es cr√≠tico para proyectos reales

3. **De negocio:**
   - Los factores econ√≥micos (oro) son m√°s predictivos que m√©tricas de combate
   - Las diferencias entre equipos son m√°s informativas que valores absolutos
   - La ventaja temprana se compone exponencialmente

---

## 7. Referencias

### Bibliograf√≠a

1. Chapman, P., et al. (2000). CRISP-DM 1.0: Step-by-step data mining guide.
2. Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning.
3. G√©ron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow.
4. McKinney, W. (2017). Python for Data Analysis.

### Recursos T√©cnicos

1. Kedro Documentation: https://kedro.readthedocs.io/
2. Scikit-learn Documentation: https://scikit-learn.org/stable/
3. Apache Airflow Documentation: https://airflow.apache.org/docs/
4. Docker Documentation: https://docs.docker.com/

### Datos

1. League of Legends Worlds Dataset: Partidas profesionales del torneo mundial
2. Riot Games API: https://developer.riotgames.com/

---

## 8. Anexos

### Anexo A: Comandos de Ejecuci√≥n

```bash
# Ejecuci√≥n completa
kedro run

# Por pipeline
kedro run --pipeline data_cleaning
kedro run --pipeline data_exploration
kedro run --pipeline data_processing
kedro run --pipeline data_science
kedro run --pipeline evaluation

# Docker + Airflow
docker-compose up -d
```

### Anexo B: Estructura de Archivos

Ver archivo `README.md` para estructura completa del proyecto.

### Anexo C: M√©tricas Detalladas

Ver archivos en `data/08_reporting/`:
- `classification_report.json`
- `regression_report.json`
- `classification_metrics.parquet`
- `regression_metrics.parquet`

### Anexo D: C√≥digo Fuente

Todo el c√≥digo est√° disponible en:
- GitHub: https://github.com/glYohanny/Evaluacion_machine_learning
- Carpeta `src/league_project/pipelines/`

---

## Declaraci√≥n de Autor√≠a

Yo, Pedro Torres (glYohanny), declaro que este trabajo es de mi autor√≠a y ha sido desarrollado siguiendo las normas acad√©micas de DuocUC. Todo el c√≥digo, documentaci√≥n y an√°lisis presentados en este informe son producto de mi trabajo individual.

**Firma:** _____________________  
**Fecha:** Octubre 27, 2025

---

**Fin del Informe**


