# üöÄ Instrucciones de Ejecuci√≥n - Soluci√≥n a Errores de Airflow

## ‚ö†Ô∏è Problema Detectado

Los DAGs de Airflow est√°n fallando porque **no encuentran el comando `kedro`** dentro de los contenedores.

### **Error Identificado:**
```
bash: kedro: command not found
```

**Causa:** El contenedor de Airflow no tiene acceso al ejecutable de Kedro.

---

## ‚úÖ Soluci√≥n Implementada

He corregido los **3 archivos DAG** para usar la ruta correcta del proyecto:
- ‚úÖ `airflow/dags/kedro_eda_only_dag.py`
- ‚úÖ `airflow/dags/kedro_league_ml_dag.py`
- ‚úÖ `airflow/dags/kedro_training_only_dag.py`

**Cambio aplicado:**
```python
# ‚ùå ANTES (INCORRECTO):
bash_command='cd /opt/airflow/kedro_project && kedro run --pipeline eda'

# ‚úÖ AHORA (CORRECTO):
bash_command='cd /app && kedro run --pipeline eda'
```

---

## üîß Pasos para Aplicar la Correcci√≥n

### **Paso 1: Reiniciar Airflow**

```powershell
# Detener todos los servicios
docker-compose down

# Reiniciar los servicios
docker-compose up -d

# Esperar 30 segundos para que todo se inicialice
Start-Sleep -Seconds 30
```

### **Paso 2: Verificar que los DAGs est√°n actualizados**

```powershell
# Ver logs del scheduler
docker-compose logs airflow-scheduler | Select-String "DAG"
```

Deber√≠as ver mensajes indicando que los DAGs se est√°n procesando.

### **Paso 3: Ejecutar el Pipeline EDA (Recomendado para probar)**

**Opci√≥n A: Desde Airflow UI**
1. Abre http://localhost:8080
2. Login: `admin` / `admin`
3. Busca `kedro_eda_pipeline`
4. Click en el toggle para activarlo (debe ponerse azul)
5. Click en "‚ñ∂Ô∏è Trigger DAG"
6. Monitorea en "Graph View"

**Opci√≥n B: Desde PowerShell**
```powershell
# Trigger el DAG desde CLI
docker-compose exec airflow-scheduler airflow dags trigger kedro_eda_pipeline

# Ver logs en tiempo real
docker-compose logs -f airflow-worker
```

---

## üîç Verificaci√≥n de Datos

Antes de ejecutar, aseg√∫rate de que los **datos RAW existen**:

```powershell
# Verificar que existen los archivos CSV
dir ..\league-of-legends-worlds\data\01_raw\*.csv
```

**Archivos necesarios:**
- ‚úÖ `champions_stats.csv`
- ‚úÖ `matches_stats.csv`
- ‚úÖ `players_stats.csv`

Si **NO existen**, necesitas copiarlos desde la carpeta original:

```powershell
# Copiar datos desde la carpeta original
Copy-Item -Path "..\league-of-legends-worlds\data\01_raw\*" -Destination ".\data\01_raw\" -Force
```

---

## üìä Pipelines Disponibles

### 1Ô∏è‚É£ **Pipeline EDA** (Recomendado para empezar)
```powershell
# Duraci√≥n: ~3 minutos
# Qu√© hace: Limpieza + An√°lisis exploratorio
docker-compose exec airflow-scheduler airflow dags trigger kedro_eda_pipeline
```

**Reportes generados:**
- `data/08_reporting/descriptive_statistics.csv`
- `data/08_reporting/team_performance_analysis.csv`
- `data/08_reporting/champion_bans_analysis.csv`

### 2Ô∏è‚É£ **Pipeline Completo** (Todo el ML)
```powershell
# Duraci√≥n: ~15 minutos
# Qu√© hace: Limpieza ‚Üí EDA ‚Üí Features ‚Üí Modelos ‚Üí Evaluaci√≥n
docker-compose exec airflow-scheduler airflow dags trigger kedro_league_ml_pipeline
```

**Reportes generados:**
- Todos los anteriores +
- `data/08_reporting/regression_metrics.csv`
- `data/08_reporting/classification_metrics.csv`
- 10 modelos en `data/06_models/`

### 3Ô∏è‚É£ **Solo Modelos** (Sin reprocesar datos)
```powershell
# Duraci√≥n: ~8 minutos
# Qu√© hace: Feature engineering ‚Üí Entrenar ‚Üí Evaluar
docker-compose exec airflow-scheduler airflow dags trigger kedro_model_training_pipeline
```

---

## üêõ Troubleshooting

### **Problema 1: "kedro: command not found"**

**Soluci√≥n:** Los DAGs ya est√°n corregidos. Solo necesitas reiniciar Airflow:
```powershell
docker-compose restart airflow-scheduler airflow-worker
```

### **Problema 2: "No such file or directory: data/01_raw/..."**

**Soluci√≥n:** Los datos no est√°n en la ubicaci√≥n correcta. C√≥pialos:
```powershell
Copy-Item -Path "..\league-of-legends-worlds\data\01_raw\*" -Destination ".\data\01_raw\" -Force
```

### **Problema 3: DAG sigue fallando despu√©s de reiniciar**

**Ver logs detallados:**
```powershell
# Logs del worker (ejecuta las tareas)
docker-compose logs airflow-worker | Select-String "ERROR"

# Logs del scheduler
docker-compose logs airflow-scheduler | Select-String "ERROR"

# Logs del kedro-app
docker-compose logs kedro-app
```

### **Problema 4: "Permission denied"**

**Soluci√≥n:** Verifica permisos de carpetas:
```powershell
# Dar permisos a las carpetas de datos
icacls ".\data" /grant Everyone:F /T
```

---

## üéØ Ejecuci√≥n Alternativa (Sin Docker)

Si Docker sigue dando problemas, puedes ejecutar Kedro **directamente**:

```powershell
# 1. Navegar al proyecto
cd C:\Users\pedri\OneDrive\Desktop\Proyecto_machine_learnig

# 2. Activar virtual environment
.\venv\Scripts\Activate.ps1

# 3. Navegar a la carpeta del proyecto
cd league-project

# 4. Ejecutar pipeline EDA
kedro run --pipeline eda

# 5. Ver reportes generados
dir data\08_reporting\*.csv
```

**Ventajas:**
- ‚úÖ M√°s r√°pido (sin Docker)
- ‚úÖ M√°s f√°cil de debuggear
- ‚úÖ Acceso directo a los datos

**Desventajas:**
- ‚ùå Sin automatizaci√≥n de Airflow
- ‚ùå Sin scheduling
- ‚ùå Sin interfaz gr√°fica

---

## üìà Verificar Resultados

### **1. Verificar que los reportes se generaron:**

```powershell
# Listar reportes generados
dir data\08_reporting\*.csv
dir data\08_reporting\*.json
```

**Deber√≠as ver:**
```
descriptive_statistics.csv
team_performance_analysis.csv
champion_bans_analysis.csv
correlations_analysis.csv
game_duration_analysis.csv
eda_complete_report.json
```

### **2. Ver contenido de un reporte:**

```powershell
# Ver estad√≠sticas descriptivas
Get-Content data\08_reporting\descriptive_statistics.csv | Select-Object -First 10

# Ver an√°lisis de equipos
Get-Content data\08_reporting\team_performance_analysis.csv | Select-Object -First 10
```

### **3. Verificar modelos entrenados (si ejecutaste pipeline completo):**

```powershell
# Listar modelos guardados
dir data\06_models\*.pkl
```

**Deber√≠as ver 10 modelos:**
- `linear_regression.pkl`
- `ridge_regression.pkl`
- `lasso_regression.pkl`
- `random_forest_regressor.pkl`
- `gradient_boosting_regressor.pkl`
- `logistic_regression.pkl`
- `random_forest_classifier.pkl`
- `gradient_boosting_classifier.pkl`
- `svm.pkl`
- `naive_bayes.pkl`

---

## üìû Resumen de Comandos √ötiles

```powershell
# REINICIAR TODO
docker-compose down && docker-compose up -d

# VER LOGS EN TIEMPO REAL
docker-compose logs -f airflow-worker

# EJECUTAR PIPELINE EDA
docker-compose exec airflow-scheduler airflow dags trigger kedro_eda_pipeline

# EJECUTAR PIPELINE COMPLETO
docker-compose exec airflow-scheduler airflow dags trigger kedro_league_ml_pipeline

# VER ESTADO DE LOS DAGS
docker-compose exec airflow-scheduler airflow dags list

# VER REPORTES GENERADOS
dir data\08_reporting\

# DETENER TODO
docker-compose down
```

---

## üéì Pr√≥ximos Pasos

Una vez que el pipeline EDA funcione:

1. ‚úÖ **Revisar los reportes** en `data/08_reporting/`
2. ‚úÖ **Ejecutar el pipeline completo** para entrenar modelos
3. ‚úÖ **Analizar las m√©tricas** de los 10 modelos
4. ‚úÖ **Preparar la presentaci√≥n** con los resultados

---

## üìÑ Documentos Relacionados

- `SOLUCION_ERROR_AIRFLOW.md` - Explicaci√≥n t√©cnica del error
- `EVALUACION_PARCIAL_CUMPLIMIENTO.md` - Verificaci√≥n de requisitos
- `README_COMPLETO.md` - Documentaci√≥n t√©cnica completa
- `GUIA_PRESENTACION.md` - Script para tu presentaci√≥n

---

**√öltima actualizaci√≥n:** Octubre 27, 2025  
**Estado de correcci√≥n:** ‚úÖ Aplicada  
**Acci√≥n requerida:** Reiniciar Airflow con `docker-compose down && docker-compose up -d`

