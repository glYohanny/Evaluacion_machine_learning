# ğŸ® League of Legends ML Project - GuÃ­a Completa de EjecuciÃ³n

## ğŸ“‹ Ãndice
1. [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Requisitos Previos](#requisitos-previos)
4. [InstalaciÃ³n](#instalaciÃ³n)
5. [EjecuciÃ³n del Proyecto](#ejecuciÃ³n-del-proyecto)
6. [Estructura de Datos](#estructura-de-datos)
7. [Pipelines Implementados](#pipelines-implementados)
8. [Modelos de Machine Learning](#modelos-de-machine-learning)
9. [Resultados y Reportes](#resultados-y-reportes)
10. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Sistema completo de Machine Learning para anÃ¡lisis y predicciÃ³n de partidas de League of Legends, implementado con **Kedro**, **Docker** y **Apache Airflow**.

### Objetivos
- **PredicciÃ³n de duraciÃ³n de partidas** (RegresiÃ³n)
- **PredicciÃ³n del equipo ganador** (ClasificaciÃ³n)
- **AnÃ¡lisis exploratorio** de estadÃ­sticas de Worlds
- **Sistema automatizado** de entrenamiento y evaluaciÃ³n

### MetodologÃ­a
ImplementaciÃ³n completa de **CRISP-DM**:
1. Business Understanding
2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      APACHE AIRFLOW                         â”‚
â”‚              (OrquestaciÃ³n y Scheduling)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KEDRO PIPELINES                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Data    â”‚â†’ â”‚   Data   â”‚â†’ â”‚   Data   â”‚â†’ â”‚   Data   â”‚  â”‚
â”‚  â”‚Cleaning  â”‚  â”‚Explorationâ”‚  â”‚Processingâ”‚  â”‚  Science â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                  â†“          â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                         â”‚  Evaluation  â”‚   â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DOCKER CONTAINERS                         â”‚
â”‚  â€¢ PostgreSQL (Base de datos Airflow)                      â”‚
â”‚  â€¢ Redis (Message broker)                                  â”‚
â”‚  â€¢ Kedro App (AplicaciÃ³n ML)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Requisitos Previos

### Software Necesario
1. **Docker Desktop** (Windows 10/11)
   - Descargar: https://www.docker.com/products/docker-desktop
   - VersiÃ³n mÃ­nima: 20.10.x
   - WSL 2 habilitado

2. **PowerShell** (Incluido en Windows)
   - VersiÃ³n mÃ­nima: 5.1

3. **Git** (Opcional, para control de versiones)
   - Descargar: https://git-scm.com/downloads

### Especificaciones Hardware
- **RAM**: MÃ­nimo 8GB (Recomendado 16GB)
- **Disco**: 10GB libres
- **CPU**: 4 cores o mÃ¡s

---

## ğŸ“¥ InstalaciÃ³n

### Paso 1: Verificar Docker
```powershell
# Abrir PowerShell y verificar
docker --version
docker-compose --version
```

**Salida esperada:**
```
Docker version 24.x.x
Docker Compose version v2.x.x
```

### Paso 2: Clonar/Descargar el Proyecto
```powershell
# Si usas Git
git clone <repository-url>
cd league-project

# O simplemente navega a la carpeta del proyecto
cd C:\Users\pedri\OneDrive\Desktop\Proyecto_machine_learnig\league-project
```

### Paso 3: ConfiguraciÃ³n Inicial
```powershell
# Ejecutar script de setup (hace todo automÃ¡ticamente)
.\setup_airflow_windows.ps1
```

**Â¿QuÃ© hace este script?**
1. âœ… Verifica Docker Desktop
2. âœ… Crea archivo `.env` con variables de entorno
3. âœ… Crea directorios de Airflow
4. âœ… Construye la imagen Docker de Kedro
5. âœ… Inicializa la base de datos de Airflow
6. âœ… Crea usuario admin de Airflow

**Tiempo estimado:** 5-10 minutos

---

## ğŸš€ EjecuciÃ³n del Proyecto

### OpciÃ³n 1: Sistema Completo con Airflow (Recomendado)

#### 1. Iniciar Servicios Docker
```powershell
docker-compose up -d
```

**Servicios que se inician:**
- `postgres` - Base de datos
- `redis` - Message broker
- `airflow-webserver` - UI de Airflow (puerto 8080)
- `airflow-scheduler` - Programador de tareas
- `airflow-worker` - Ejecutor de tareas
- `kedro-app` - AplicaciÃ³n ML

#### 2. Acceder a Airflow
- **URL**: http://localhost:8080
- **Usuario**: `admin`
- **Password**: `admin`

#### 3. Ejecutar Pipelines

**Desde Airflow UI:**
1. Ve a la lista de DAGs
2. Activa el DAG que quieras ejecutar (toggle ON)
3. Click en el nombre del DAG
4. Click en "â–¶ï¸ Trigger DAG"

**DAGs Disponibles:**

##### a) `kedro_eda_pipeline` (AnÃ¡lisis Exploratorio)
- **DuraciÃ³n:** ~3 minutos
- **QuÃ© hace:**
  - Limpia datos raw
  - Genera estadÃ­sticas descriptivas
  - Analiza equipos y campeones
  - Crea reportes de calidad de datos
- **CuÃ¡ndo usarlo:** ExploraciÃ³n inicial de datos

##### b) `kedro_league_ml_pipeline` (Pipeline Completo)
- **DuraciÃ³n:** ~15 minutos
- **QuÃ© hace:**
  - Limpieza de datos
  - AnÃ¡lisis exploratorio
  - Feature engineering
  - Entrenamiento de 10 modelos
  - EvaluaciÃ³n y reportes
- **CuÃ¡ndo usarlo:** Entrenamiento completo end-to-end

##### c) `kedro_model_training_pipeline` (Solo Modelos)
- **DuraciÃ³n:** ~8 minutos
- **QuÃ© hace:**
  - Feature engineering
  - Entrenamiento de modelos
  - EvaluaciÃ³n de modelos
- **CuÃ¡ndo usarlo:** Reentrenar modelos sin reprocesar datos

#### 4. Monitorear EjecuciÃ³n
- **Graph View**: Ver flujo de tareas
- **Logs**: Click en tarea â†’ "Log" para ver detalles
- **Grid View**: Historial de ejecuciones

#### 5. Detener Servicios
```powershell
docker-compose down
```

---

### OpciÃ³n 2: EjecuciÃ³n Directa con Kedro (Sin Docker)

#### 1. Activar Entorno Virtual
```powershell
# Navegar al directorio del proyecto
cd C:\Users\pedri\OneDrive\Desktop\Proyecto_machine_learnig

# Activar virtual environment
.\venv\Scripts\Activate.ps1
```

#### 2. Instalar Dependencias
```powershell
pip install -r league-project/requirements.txt
```

#### 3. Navegar a la Carpeta del Proyecto
```powershell
cd league-project
```

#### 4. Ejecutar Pipelines

**Pipeline Completo:**
```powershell
kedro run
```

**Pipelines Individuales:**
```powershell
# Solo limpieza de datos
kedro run --pipeline data_cleaning

# Solo anÃ¡lisis exploratorio
kedro run --pipeline data_exploration

# Limpieza + ExploraciÃ³n
kedro run --pipeline eda

# Feature engineering
kedro run --pipeline data_processing

# Entrenamiento de modelos
kedro run --pipeline data_science

# EvaluaciÃ³n de modelos
kedro run --pipeline evaluation
```

**Ejecutar Nodos EspecÃ­ficos:**
```powershell
# Desde un nodo especÃ­fico
kedro run --from-nodes clean_main_dataset_node

# Hasta un nodo especÃ­fico
kedro run --to-nodes generate_eda_report_node

# Solo un nodo
kedro run --node clean_main_dataset_node
```

---

## ğŸ“Š Estructura de Datos

### Datos de Entrada (data/01_raw/)
```
data/01_raw/
â”œâ”€â”€ LeagueofLegends.csv      # Dataset principal (10,000+ partidas)
â”œâ”€â”€ matchinfo.csv            # InformaciÃ³n de partidas
â”œâ”€â”€ bans.csv                 # Campeones baneados
â”œâ”€â”€ gold.csv                 # EconomÃ­a del juego
â”œâ”€â”€ kills.csv                # Asesinatos y kills
â”œâ”€â”€ monsters.csv             # Objetivos neutrales
â””â”€â”€ structures.csv           # Torres e inhibidores
```

### Datos Procesados

#### data/02_intermediate/ (Datos Limpios)
- `main_clean.csv`
- `matchinfo_clean.csv`
- `bans_clean.csv`, etc.

#### data/05_model_input/ (Features para ML)
- `worlds_final.csv` - Dataset consolidado con features

#### data/06_models/ (Modelos Entrenados)
- `linear_regression.pkl`
- `random_forest_regressor.pkl`
- `logistic_regression.pkl`
- `random_forest_classifier.pkl`, etc.

#### data/08_reporting/ (Reportes y MÃ©tricas)
- `descriptive_statistics.csv`
- `team_performance_analysis.csv`
- `champion_bans_analysis.csv`
- `regression_metrics.csv`
- `classification_metrics.csv`
- `eda_complete_report.json`

---

## ğŸ”„ Pipelines Implementados

### 1. Data Cleaning Pipeline
**Objetivo:** Limpiar datos raw y prepararlos para anÃ¡lisis

**Nodos (8):**
1. `clean_main_dataset` - Limpia dataset principal
2. `clean_matchinfo` - Limpia info de partidas
3. `clean_bans` - Limpia datos de bans
4. `clean_gold` - Limpia datos de oro
5. `clean_kills` - Limpia datos de kills
6. `clean_monsters` - Limpia objetivos neutrales
7. `clean_structures` - Limpia estructuras
8. `generate_data_quality_report` - Genera reporte de calidad

**TÃ©cnicas Aplicadas:**
- EliminaciÃ³n de duplicados
- ImputaciÃ³n de valores nulos
- DetecciÃ³n de outliers (mÃ©todo IQR)
- ValidaciÃ³n de tipos de datos

**DuraciÃ³n:** ~1 minuto

---

### 2. Data Exploration Pipeline
**Objetivo:** AnÃ¡lisis exploratorio de datos limpios

**Nodos (8):**
1. `generate_descriptive_statistics` - EstadÃ­sticas descriptivas
2. `analyze_team_performance` - AnÃ¡lisis de equipos (246 equipos)
3. `analyze_champion_bans` - AnÃ¡lisis de bans (137 campeones)
4. `analyze_neutral_objectives` - Dragones, Barones, Heralds
5. `analyze_structures` - Torres e inhibidores
6. `analyze_correlations` - Matriz de correlaciÃ³n
7. `analyze_game_duration` - AnÃ¡lisis temporal
8. `generate_eda_report` - Reporte completo JSON

**AnÃ¡lisis Generados:**
- Media, mediana, desviaciÃ³n estÃ¡ndar
- Win rate por equipo
- Frecuencia de bans por campeÃ³n
- Correlaciones entre variables
- DistribuciÃ³n de duraciÃ³n de partidas

**DuraciÃ³n:** ~2 minutos

---

### 3. Data Processing Pipeline
**Objetivo:** Feature engineering y preparaciÃ³n para ML

**Nodos (7):**
1. `aggregate_kills` - Agrega kills por equipo
2. `aggregate_monsters` - Agrega objetivos neutrales
3. `aggregate_structures` - Agrega estructuras
4. `aggregate_gold` - Agrega economÃ­a
5. `select_features` - Selecciona features relevantes
6. `split_data` - Train/test split (80/20)
7. `scale_features` - NormalizaciÃ³n de features

**Features Creadas:**
- Diferencia de kills (blue - red)
- Diferencia de dragones
- Diferencia de barones
- Diferencia de torres
- Diferencia de oro

**DuraciÃ³n:** ~2 minutos

---

### 4. Data Science Pipeline
**Objetivo:** Entrenamiento de modelos de ML

**Modelos de RegresiÃ³n (5):**
1. Linear Regression
2. Ridge Regression
3. Lasso Regression
4. Random Forest Regressor
5. Gradient Boosting Regressor

**Modelos de ClasificaciÃ³n (5):**
1. Logistic Regression
2. Random Forest Classifier
3. Gradient Boosting Classifier
4. Support Vector Machine (SVM)
5. Naive Bayes

**DuraciÃ³n:** ~8 minutos

---

### 5. Evaluation Pipeline
**Objetivo:** EvaluaciÃ³n de modelos y generaciÃ³n de reportes

**MÃ©tricas de RegresiÃ³n:**
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- RÂ² (Coeficiente de DeterminaciÃ³n)

**MÃ©tricas de ClasificaciÃ³n:**
- Accuracy
- Precision
- Recall
- F1-Score
- AUC-ROC

**Reportes Generados:**
- Feature importance (modelos basados en Ã¡rboles)
- ComparaciÃ³n de modelos
- Reporte JSON completo

**DuraciÃ³n:** ~2 minutos

---

## ğŸ¤– Modelos de Machine Learning

### Problema 1: PredicciÃ³n de DuraciÃ³n (RegresiÃ³n)
**Target:** `gamelength_minutes`

| Modelo | RMSE | MAE | RÂ² | DescripciÃ³n |
|--------|------|-----|-------|------------|
| Linear Regression | ~X.X | ~X.X | ~0.XX | Baseline simple |
| Ridge Regression | ~X.X | ~X.X | ~0.XX | RegularizaciÃ³n L2 |
| Lasso Regression | ~X.X | ~X.X | ~0.XX | RegularizaciÃ³n L1 |
| Random Forest | ~X.X | ~X.X | ~0.XX | Ensemble de Ã¡rboles |
| Gradient Boosting | ~X.X | ~X.X | ~0.XX | Boosting iterativo |

### Problema 2: PredicciÃ³n de Ganador (ClasificaciÃ³n)
**Target:** `bresult` (1 = Blue gana, 0 = Red gana)

| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Logistic Regression | ~X.XX | ~X.XX | ~X.XX | ~X.XX |
| Random Forest | ~X.XX | ~X.XX | ~X.XX | ~X.XX |
| Gradient Boosting | ~X.XX | ~X.XX | ~X.XX | ~X.XX |
| SVM | ~X.XX | ~X.XX | ~X.XX | ~X.XX |
| Naive Bayes | ~X.XX | ~X.XX | ~X.XX | ~X.XX |

**Nota:** Los valores exactos se encuentran en `data/08_reporting/regression_metrics.csv` y `classification_metrics.csv`

---

## ğŸ“ˆ Resultados y Reportes

### Acceder a Resultados

#### 1. Desde Airflow
- Ve a "Browse" â†’ "Data" â†’ Busca el dataset de reporte
- Descarga el CSV o JSON

#### 2. Directamente en el Sistema de Archivos
```powershell
# Ver reportes
cd data/08_reporting
dir

# Abrir reporte CSV
notepad descriptive_statistics.csv

# Abrir reporte JSON
notepad eda_complete_report.json
```

### Reportes Clave

#### data/08_reporting/team_performance_analysis.csv
```csv
team,total_games,wins,losses,win_rate,avg_game_length
T1,50,35,15,0.700,32.5
GEN,48,32,16,0.667,31.8
...
```

#### data/08_reporting/regression_metrics.csv
```csv
model,rmse,mae,r2_train,r2_test
linear_regression,5.2,4.1,0.82,0.78
random_forest,3.8,2.9,0.91,0.85
...
```

#### data/08_reporting/classification_metrics.csv
```csv
model,accuracy,precision,recall,f1_score,auc_roc
logistic_regression,0.85,0.84,0.86,0.85,0.89
random_forest,0.89,0.88,0.90,0.89,0.94
...
```

---

## ğŸ”§ Troubleshooting

### Problema 1: Docker no estÃ¡ instalado
**Error:** `docker : El tÃ©rmino 'docker' no se reconoce...`

**SoluciÃ³n:**
1. Instalar Docker Desktop: https://www.docker.com/products/docker-desktop
2. Reiniciar la computadora
3. Verificar: `docker --version`

---

### Problema 2: Puerto 8080 ocupado
**Error:** `Bind for 0.0.0.0:8080 failed: port is already allocated`

**SoluciÃ³n:**
```powershell
# OpciÃ³n 1: Detener el servicio que usa el puerto
netstat -ano | findstr :8080
taskkill /PID <PID> /F

# OpciÃ³n 2: Cambiar puerto en docker-compose.yml
# Editar lÃ­nea:
ports:
  - "8081:8080"  # Usar 8081 en lugar de 8080
```

---

### Problema 3: Kedro no encuentra datasets
**Error:** `Pipeline input(s) {'raw_main_data'} not found...`

**SoluciÃ³n:**
```powershell
# Verificar que existen los datos
dir data\01_raw

# Verificar configuraciÃ³n del catÃ¡logo
notepad conf\base\catalog.yml

# Re-ejecutar con verbose
kedro run --pipeline data_cleaning -v
```

---

### Problema 4: Memoria insuficiente
**Error:** Container killed (OOMKilled)

**SoluciÃ³n:**
1. Abrir Docker Desktop
2. Settings â†’ Resources
3. Aumentar Memory a 8GB o mÃ¡s
4. Apply & Restart

---

### Problema 5: Airflow no muestra DAGs
**SoluciÃ³n:**
```powershell
# Reiniciar scheduler
docker-compose restart airflow-scheduler

# Ver logs del scheduler
docker-compose logs airflow-scheduler

# Verificar que los DAGs estÃ¡n en la carpeta correcta
dir airflow\dags
```

---

## ğŸ“š Comandos Ãštiles

### Docker
```powershell
# Ver servicios corriendo
docker-compose ps

# Ver logs de un servicio
docker-compose logs airflow-webserver
docker-compose logs kedro-app

# Reiniciar un servicio
docker-compose restart airflow-scheduler

# Detener todos los servicios
docker-compose down

# Detener y eliminar volÃºmenes
docker-compose down -v

# Reconstruir imagen
docker-compose build kedro-app
```

### Kedro
```powershell
# Ver pipelines disponibles
kedro registry list

# Ver catÃ¡logo de datos
kedro catalog list

# Ver estructura del proyecto
kedro catalog ds --pipeline data_cleaning

# Ejecutar con mÃ¡s informaciÃ³n
kedro run --pipeline eda -v

# Limpiar archivos temporales
kedro clean
```

### Airflow CLI (dentro del container)
```powershell
# Entrar al container
docker-compose exec airflow-webserver bash

# Listar DAGs
airflow dags list

# Probar un DAG
airflow dags test kedro_eda_pipeline 2024-01-01

# Ver tareas de un DAG
airflow tasks list kedro_eda_pipeline
```

---

## ğŸ“ Contacto y Soporte

**Autor:** Pedro (Tu nombre completo)  
**Email:** tu_email@ejemplo.com  
**GitHub:** https://github.com/tu-usuario/league-ml-project  

---

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico para el curso de Machine Learning.

---

## ğŸ“ Referencias

1. Kedro Documentation: https://kedro.readthedocs.io/
2. Apache Airflow Documentation: https://airflow.apache.org/docs/
3. Docker Documentation: https://docs.docker.com/
4. Scikit-learn Documentation: https://scikit-learn.org/stable/

---

**Ãšltima actualizaciÃ³n:** Octubre 2024  
**VersiÃ³n:** 1.0.0

